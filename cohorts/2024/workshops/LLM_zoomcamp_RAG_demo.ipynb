{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Intro dlt -> LanceDB loading example"
      ],
      "metadata": {
        "id": "Y2-47Y87jwW_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://lu.ma/cnpdoc5n\n",
        "\n",
        "If you want to play around with this notebook and make edits in future, we highly recommend making a copy since the link is view only! Also make sure you're signed in with your Google account to be able to add secrets.\n",
        "\n",
        "Before going into a more complex example, we will go through a simple example of how to load the course Q&A data into LanceDB."
      ],
      "metadata": {
        "id": "hjkkr8_UH0K_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install requirements"
      ],
      "metadata": {
        "id": "K3VvFlhSbRYx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To create a json -> lancedb pipeline, we need to install:\n",
        "1. dlt with lancedb extras\n",
        "2. sentence-transformers: we need to use an embedding model to vectorize and store data inside LanceDB. For this we choose the open-source model \"sentence-transformers/all-MiniLM-L6-v2\"."
      ],
      "metadata": {
        "id": "OSlHmqELbQHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install dlt[lancedb]==0.5.1a0\n",
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "vcQ6QseXKSHX"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the data"
      ],
      "metadata": {
        "id": "roJHcRy0bW95"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll first load the data just into LanceDB, without embedding it. LanceDB stores both the data and the embeddings, and can also embed data and queries on the fly.\n",
        "\n",
        "Some definitions:\n",
        "* A dlt **source** is a grouping of **resources** (e.g. all your data from Hubspot)\n",
        "* A dlt **resource** is a function that yields data (e.g. a function yielding all your Hubspot companies)\n",
        "* A dlt **pipeline** is how you ingest your data\n",
        "\n",
        "Loading the data consists of a few steps:\n",
        "1. Use the requests library to get the data\n",
        "2. Define a dlt resource that yields the individual documents\n",
        "3. Create a dlt pipeline and run it"
      ],
      "metadata": {
        "id": "c5-X9owIbsAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import dlt\n",
        "\n",
        "qa_dataset = requests.get(\"https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1\").json()\n",
        "\n",
        "@dlt.resource\n",
        "def qa_documents():\n",
        "  for course in qa_dataset:\n",
        "    yield course[\"documents\"]\n",
        "\n",
        "pipeline = dlt.pipeline(pipeline_name=\"from_json\", destination=\"lancedb\", dataset_name=\"qanda\")\n",
        "\n",
        "load_info = pipeline.run(qa_documents, table_name=\"documents\")\n",
        "\n",
        "print(load_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CTfhhFGJ-ma",
        "outputId": "6b31862d-d7c9-40fc-f9a2-6873367efa9d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline from_json load step completed in 0.20 seconds\n",
            "1 load package(s) were loaded to destination LanceDB and into dataset qanda\n",
            "The LanceDB destination used <dlt.destinations.impl.lancedb.configuration.LanceDBCredentials object at 0x7c6f6f75cfa0> location to store data\n",
            "Load package 1721587903.519054 is LOADED and contains no failed jobs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lancedb\n",
        "\n",
        "db = lancedb.connect(\"./.lancedb\")\n",
        "print(db.table_names())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOuo4R7XNH9y",
        "outputId": "72269845-9cec-4d45-e180-482e427ffc61"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['notion_pages____dlt_loads', 'notion_pages____dlt_pipeline_state', 'notion_pages____dlt_version', 'notion_pages___dltSentinelTable', 'notion_pages___employee_handbook', 'notion_pages___homework', 'qanda____dlt_loads', 'qanda____dlt_pipeline_state', 'qanda____dlt_version', 'qanda___dltSentinelTable', 'qanda___documents', 'qanda_embedded____dlt_loads', 'qanda_embedded____dlt_pipeline_state', 'qanda_embedded____dlt_version', 'qanda_embedded___dltSentinelTable', 'qanda_embedded___documents']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db_table = db.open_table(\"qanda___documents\")\n",
        "\n",
        "db_table.to_pandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PQwiUyt_Pb_H",
        "outputId": "9b270d47-452c-411b-b2dd-7e3f7c1f0793"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      id__  \\\n",
              "0     5f0b32ab-a0cb-5d16-a9ee-8df861a92c93   \n",
              "1     5edc6f08-038c-5db8-96c3-67fc4ea6f378   \n",
              "2     b2022b73-5b93-5883-b859-6faa926fcf5d   \n",
              "3     26ef9634-d7b9-5555-b467-932f8c65ca9c   \n",
              "4     76e76695-313c-5a41-ba08-28da672a312e   \n",
              "...                                    ...   \n",
              "1891  4f4744b4-ff49-549a-ad8c-034a89e5726c   \n",
              "1892  68981b41-10b3-5d80-a0da-51d6fbbfa6eb   \n",
              "1893  a373c3ac-f4b5-5a52-a91f-d0fc51990a82   \n",
              "1894  b8ee4203-5db3-5004-b43a-ef4e69098485   \n",
              "1895  ecbc1d13-3b42-547e-8576-57075c4365ea   \n",
              "\n",
              "                                                   text  \\\n",
              "0     The purpose of this document is to capture fre...   \n",
              "1     GitHub - DataTalksClub data-engineering-zoomca...   \n",
              "2     Yes, even if you don't register, you're still ...   \n",
              "3     You don't need it. You're accepted. You can al...   \n",
              "4     You can start by installing and setting up all...   \n",
              "...                                                 ...   \n",
              "1891  Problem description\\nThis is the step in the c...   \n",
              "1892  Problem description\\nWhen a docker-compose fil...   \n",
              "1893  Problem description\\nIf you are having problem...   \n",
              "1894  Problem description\\nPre-commit command was fa...   \n",
              "1895  Problem description\\nInfrastructure created in...   \n",
              "\n",
              "                               section  \\\n",
              "0     General course-related questions   \n",
              "1     General course-related questions   \n",
              "2     General course-related questions   \n",
              "3     General course-related questions   \n",
              "4     General course-related questions   \n",
              "...                                ...   \n",
              "1891          Module 6: Best practices   \n",
              "1892          Module 6: Best practices   \n",
              "1893          Module 6: Best practices   \n",
              "1894          Module 6: Best practices   \n",
              "1895          Module 6: Best practices   \n",
              "\n",
              "                                               question        _dlt_load_id  \\\n",
              "0                  Course - When will the course start?  1721585667.5490527   \n",
              "1     Course - What are the prerequisites for this c...  1721585667.5490527   \n",
              "2     Course - Can I still join the course after the...  1721585667.5490527   \n",
              "3     Course - I have registered for the Data Engine...  1721585667.5490527   \n",
              "4      Course - What can I do before the course starts?  1721585667.5490527   \n",
              "...                                                 ...                 ...   \n",
              "1891  Github actions: Permission denied error when e...   1721587903.519054   \n",
              "1892  Managing Multiple Docker Containers with docke...   1721587903.519054   \n",
              "1893           AWS regions need to match docker-compose   1721587903.519054   \n",
              "1894                                   Isort Pre-commit   1721587903.519054   \n",
              "1895  How to destroy infrastructure created via GitH...   1721587903.519054   \n",
              "\n",
              "             _dlt_id  \n",
              "0     8vuDU+9B+vF8nQ  \n",
              "1     Ae1ENT8+sEqO6w  \n",
              "2     49Cq3+kud08R1w  \n",
              "3     JN84gXbIDKtrqg  \n",
              "4     meyXoASzd041xA  \n",
              "...              ...  \n",
              "1891  031vplX8wYuYjw  \n",
              "1892  eqIS/7mxekfmag  \n",
              "1893  Rj9LnD19Y4LoeQ  \n",
              "1894  BH4fDxbJNkEyGg  \n",
              "1895  xRo8yUnZR1EAVg  \n",
              "\n",
              "[1896 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac911dd2-9a2a-4cd1-9958-7031ed82eb52\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id__</th>\n",
              "      <th>text</th>\n",
              "      <th>section</th>\n",
              "      <th>question</th>\n",
              "      <th>_dlt_load_id</th>\n",
              "      <th>_dlt_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5f0b32ab-a0cb-5d16-a9ee-8df861a92c93</td>\n",
              "      <td>The purpose of this document is to capture fre...</td>\n",
              "      <td>General course-related questions</td>\n",
              "      <td>Course - When will the course start?</td>\n",
              "      <td>1721585667.5490527</td>\n",
              "      <td>8vuDU+9B+vF8nQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5edc6f08-038c-5db8-96c3-67fc4ea6f378</td>\n",
              "      <td>GitHub - DataTalksClub data-engineering-zoomca...</td>\n",
              "      <td>General course-related questions</td>\n",
              "      <td>Course - What are the prerequisites for this c...</td>\n",
              "      <td>1721585667.5490527</td>\n",
              "      <td>Ae1ENT8+sEqO6w</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b2022b73-5b93-5883-b859-6faa926fcf5d</td>\n",
              "      <td>Yes, even if you don't register, you're still ...</td>\n",
              "      <td>General course-related questions</td>\n",
              "      <td>Course - Can I still join the course after the...</td>\n",
              "      <td>1721585667.5490527</td>\n",
              "      <td>49Cq3+kud08R1w</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26ef9634-d7b9-5555-b467-932f8c65ca9c</td>\n",
              "      <td>You don't need it. You're accepted. You can al...</td>\n",
              "      <td>General course-related questions</td>\n",
              "      <td>Course - I have registered for the Data Engine...</td>\n",
              "      <td>1721585667.5490527</td>\n",
              "      <td>JN84gXbIDKtrqg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>76e76695-313c-5a41-ba08-28da672a312e</td>\n",
              "      <td>You can start by installing and setting up all...</td>\n",
              "      <td>General course-related questions</td>\n",
              "      <td>Course - What can I do before the course starts?</td>\n",
              "      <td>1721585667.5490527</td>\n",
              "      <td>meyXoASzd041xA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1891</th>\n",
              "      <td>4f4744b4-ff49-549a-ad8c-034a89e5726c</td>\n",
              "      <td>Problem description\\nThis is the step in the c...</td>\n",
              "      <td>Module 6: Best practices</td>\n",
              "      <td>Github actions: Permission denied error when e...</td>\n",
              "      <td>1721587903.519054</td>\n",
              "      <td>031vplX8wYuYjw</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1892</th>\n",
              "      <td>68981b41-10b3-5d80-a0da-51d6fbbfa6eb</td>\n",
              "      <td>Problem description\\nWhen a docker-compose fil...</td>\n",
              "      <td>Module 6: Best practices</td>\n",
              "      <td>Managing Multiple Docker Containers with docke...</td>\n",
              "      <td>1721587903.519054</td>\n",
              "      <td>eqIS/7mxekfmag</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1893</th>\n",
              "      <td>a373c3ac-f4b5-5a52-a91f-d0fc51990a82</td>\n",
              "      <td>Problem description\\nIf you are having problem...</td>\n",
              "      <td>Module 6: Best practices</td>\n",
              "      <td>AWS regions need to match docker-compose</td>\n",
              "      <td>1721587903.519054</td>\n",
              "      <td>Rj9LnD19Y4LoeQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1894</th>\n",
              "      <td>b8ee4203-5db3-5004-b43a-ef4e69098485</td>\n",
              "      <td>Problem description\\nPre-commit command was fa...</td>\n",
              "      <td>Module 6: Best practices</td>\n",
              "      <td>Isort Pre-commit</td>\n",
              "      <td>1721587903.519054</td>\n",
              "      <td>BH4fDxbJNkEyGg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1895</th>\n",
              "      <td>ecbc1d13-3b42-547e-8576-57075c4365ea</td>\n",
              "      <td>Problem description\\nInfrastructure created in...</td>\n",
              "      <td>Module 6: Best practices</td>\n",
              "      <td>How to destroy infrastructure created via GitH...</td>\n",
              "      <td>1721587903.519054</td>\n",
              "      <td>xRo8yUnZR1EAVg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1896 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac911dd2-9a2a-4cd1-9958-7031ed82eb52')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ac911dd2-9a2a-4cd1-9958-7031ed82eb52 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ac911dd2-9a2a-4cd1-9958-7031ed82eb52');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-539caffe-3b27-40a5-8f47-931f07aa4103\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-539caffe-3b27-40a5-8f47-931f07aa4103')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-539caffe-3b27-40a5-8f47-931f07aa4103 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"db_table\",\n  \"rows\": 1896,\n  \"fields\": [\n    {\n      \"column\": \"id__\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1896,\n        \"samples\": [\n          \"b58d0c60-5783-5141-8c19-fc4a54f41de8\",\n          \"d179bf09-bea6-5cd7-9741-15ec6ee04d87\",\n          \"6fadbae4-751d-596a-908b-7793347c284f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 945,\n        \"samples\": [\n          \"Problem: The output of DictVectorizer was taking up too much memory. So much so, that I couldn\\u2019t even fit the linear regression model before running out of memory on my 16 GB machine.\\nSolution: In the example for DictVectorizer in the scikit-learn website, they set the parameter \\u201csparse\\u201d as False. Although this helps with viewing the results, this results in a lot of memory usage. The solution is to either use \\u201csparse=True\\u201d instead, or leave it at the default which is also True.\\nAhmed Fahim (afahim03@yahoo.com)\",\n          \"Link to Slack Thread : has anyone figured out how to read from GCP data lake instead of downloading all the taxi data again?\\nThere\\u2019s a few extra steps to go into reading from GCS with PySpark\\n1.)  IMPORTANT: Download the Cloud Storage connector for Hadoop here: https://cloud.google.com/dataproc/docs/concepts/connectors/cloud-storage#clusters\\nAs the name implies, this .jar file is what essentially connects PySpark with your GCS\\n2.) Move the .jar file to your Spark file directory. I installed Spark using homebrew on my MacOS machine and I had to create a /jars directory under \\\"/opt/homebrew/Cellar/apache-spark/3.2.1/ (where my spark dir is located)\\n3.) In your Python script, there are a few extra classes you\\u2019ll have to import:\\nimport pyspark\\nfrom pyspark.sql import SparkSession\\nfrom pyspark.conf import SparkConf\\nfrom pyspark.context import SparkContext\\n4.) You must set up your configurations before building your SparkSession. Here\\u2019s my code snippet:\\nconf = SparkConf() \\\\\\n.setMaster('local[*]') \\\\\\n.setAppName('test') \\\\\\n.set(\\\"spark.jars\\\", \\\"/opt/homebrew/Cellar/apache-spark/3.2.1/jars/gcs-connector-hadoop3-latest.jar\\\") \\\\\\n.set(\\\"spark.hadoop.google.cloud.auth.service.account.enable\\\", \\\"true\\\") \\\\\\n.set(\\\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\\\", \\\"path/to/google_credentials.json\\\")\\nsc = SparkContext(conf=conf)\\nsc._jsc.hadoopConfiguration().set(\\\"fs.AbstractFileSystem.gs.impl\\\",  \\\"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\\\")\\nsc._jsc.hadoopConfiguration().set(\\\"fs.gs.impl\\\", \\\"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\\\")\\nsc._jsc.hadoopConfiguration().set(\\\"fs.gs.auth.service.account.json.keyfile\\\", \\\"path/to/google_credentials.json\\\")\\nsc._jsc.hadoopConfiguration().set(\\\"fs.gs.auth.service.account.enable\\\", \\\"true\\\")\\n5.) Once you run that, build your SparkSession with the new parameters we\\u2019d just instantiated in the previous step:\\nspark = SparkSession.builder \\\\\\n.config(conf=sc.getConf()) \\\\\\n.getOrCreate()\\n6.) Finally, you\\u2019re able to read your files straight from GCS!\\ndf_green = spark.read.parquet(\\\"gs://{BUCKET}/green/202*/\\\")\",\n          \"1. Go to your dbt cloud service account\\n1. Adding the  [Storage Object Admin,Storage Admin] role in addition tco BigQuery Admin.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"section\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"Module 4: Deployment\",\n          \"3. Machine Learning for Classification\",\n          \"Miscellaneous\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 943,\n        \"samples\": [\n          \"WSL - Permissions too open at Windows\",\n          \"Why do we need the Staging dataset?\",\n          \"What if my answer is not exactly the same as the choices presented?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_dlt_load_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1721587903.519054\",\n          \"1721585667.5490527\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_dlt_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1896,\n        \"samples\": [\n          \"YxEku0XH0tq2Hg\",\n          \"T9DLwCfZLqnk6Q\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and embed the data"
      ],
      "metadata": {
        "id": "s5vK8EMfbfs2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we load the same data again (into a new table), but embed it directly with the `lancedb_adapter`. This consists of the following steps:\n",
        "\n",
        "1. Define the embedding model to use via ENV variables\n",
        "2. Define a new pipeline to load the same data and embed the \"text\" and \"question\" columns with the `lancedb_adapter`\n",
        "\n",
        "You can use any embedding model, from open source to OpenAI. We've chosen the [`all-MiniLM-L6-v2`](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) sentence transformer for speed and simplicty.\n",
        "\n",
        "Note: this pipeline runs slightly longer because it has to download the model and embed the data."
      ],
      "metadata": {
        "id": "aOXAMNAzigD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dlt.destinations.adapters import lancedb_adapter\n",
        "\n",
        "os.environ[\"DESTINATION__LANCEDB__EMBEDDING_MODEL_PROVIDER\"] = \"sentence-transformers\"\n",
        "os.environ[\"DESTINATION__LANCEDB__EMBEDDING_MODEL\"] = \"all-MiniLM-L6-v2\"\n",
        "\n",
        "pipeline = dlt.pipeline(pipeline_name=\"from_json_embedded\", destination=\"lancedb\", dataset_name=\"qanda_embedded\")\n",
        "\n",
        "load_info = pipeline.run(lancedb_adapter(qa_documents, embed=[\"text\", \"question\"]), table_name=\"documents\")\n",
        "print(load_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpqhOpmrS45-",
        "outputId": "fa57ae2a-12bb-4886-ffd1-02b5ab299f22"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline from_json_embedded load step completed in 30.38 seconds\n",
            "1 load package(s) were loaded to destination LanceDB and into dataset qanda_embedded\n",
            "The LanceDB destination used <dlt.destinations.impl.lancedb.configuration.LanceDBCredentials object at 0x7c6f6fcfe500> location to store data\n",
            "Load package 1721587904.8055472 is LOADED and contains no failed jobs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db = lancedb.connect(\"./.lancedb\")\n",
        "print(db.table_names())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnOvwU8kTBCL",
        "outputId": "efc9da75-21ac-4ef7-eaf5-cbcce2331f44"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['notion_pages____dlt_loads', 'notion_pages____dlt_pipeline_state', 'notion_pages____dlt_version', 'notion_pages___dltSentinelTable', 'notion_pages___employee_handbook', 'notion_pages___homework', 'qanda____dlt_loads', 'qanda____dlt_pipeline_state', 'qanda____dlt_version', 'qanda___dltSentinelTable', 'qanda___documents', 'qanda_embedded____dlt_loads', 'qanda_embedded____dlt_pipeline_state', 'qanda_embedded____dlt_version', 'qanda_embedded___dltSentinelTable', 'qanda_embedded___documents']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db_table = db.open_table(\"qanda_embedded___documents\")\n",
        "\n",
        "db_table.to_pandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lp4C-2h4THdK",
        "outputId": "6d6dc703-232e-4746-aad7-a3d72aa372c5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      id__  \\\n",
              "0     6176bb1f-204b-5283-9c2f-847c955b544c   \n",
              "1     6db90087-445f-5ba0-9026-4c06ab5bfd96   \n",
              "2     0387f46f-fc58-535e-8321-46076a15cfc6   \n",
              "3     78f94202-c34c-5710-bcb2-a71913d41144   \n",
              "4     7edac7bb-a692-5c48-9933-a05a0c79bcd6   \n",
              "...                                    ...   \n",
              "1891  739bfce7-8e24-5aa9-a67d-fdfa7a4e5b8b   \n",
              "1892  e8299dc0-603c-5025-9437-2909594be446   \n",
              "1893  4c627194-f4fa-545e-a0bd-0ccd53e775f8   \n",
              "1894  1850e592-c31a-5c23-b811-5548dc41fa32   \n",
              "1895  c4a194c4-eafe-5939-a721-49b249eef737   \n",
              "\n",
              "                                               vector__  \\\n",
              "0     [-0.00035094196, -0.062014297, -0.037999876, 0...   \n",
              "1     [0.020011412, -0.011535538, 0.013017209, -0.00...   \n",
              "2     [0.014857555, -0.06664993, -0.013571247, 0.023...   \n",
              "3     [-0.023312032, -0.09461493, 0.056361612, -0.00...   \n",
              "4     [0.026537651, -0.01779666, 0.0021155947, 0.006...   \n",
              "...                                                 ...   \n",
              "1891  [0.016619362, -0.033603165, -0.093347155, -0.0...   \n",
              "1892  [0.026872855, -0.0019949432, 0.008369081, -0.0...   \n",
              "1893  [0.03513756, 0.056265566, 0.024428478, -0.0651...   \n",
              "1894  [0.033809766, -0.0031219206, 0.0017484799, 0.0...   \n",
              "1895  [-0.00075231574, 0.0042315223, 0.0025023425, -...   \n",
              "\n",
              "                                                   text  \\\n",
              "0     The purpose of this document is to capture fre...   \n",
              "1     GitHub - DataTalksClub data-engineering-zoomca...   \n",
              "2     Yes, even if you don't register, you're still ...   \n",
              "3     You don't need it. You're accepted. You can al...   \n",
              "4     You can start by installing and setting up all...   \n",
              "...                                                 ...   \n",
              "1891  Problem description\\nThis is the step in the c...   \n",
              "1892  Problem description\\nWhen a docker-compose fil...   \n",
              "1893  Problem description\\nIf you are having problem...   \n",
              "1894  Problem description\\nPre-commit command was fa...   \n",
              "1895  Problem description\\nInfrastructure created in...   \n",
              "\n",
              "                               section  \\\n",
              "0     General course-related questions   \n",
              "1     General course-related questions   \n",
              "2     General course-related questions   \n",
              "3     General course-related questions   \n",
              "4     General course-related questions   \n",
              "...                                ...   \n",
              "1891          Module 6: Best practices   \n",
              "1892          Module 6: Best practices   \n",
              "1893          Module 6: Best practices   \n",
              "1894          Module 6: Best practices   \n",
              "1895          Module 6: Best practices   \n",
              "\n",
              "                                               question        _dlt_load_id  \\\n",
              "0                  Course - When will the course start?    1721585669.31219   \n",
              "1     Course - What are the prerequisites for this c...    1721585669.31219   \n",
              "2     Course - Can I still join the course after the...    1721585669.31219   \n",
              "3     Course - I have registered for the Data Engine...    1721585669.31219   \n",
              "4      Course - What can I do before the course starts?    1721585669.31219   \n",
              "...                                                 ...                 ...   \n",
              "1891  Github actions: Permission denied error when e...  1721587904.8055472   \n",
              "1892  Managing Multiple Docker Containers with docke...  1721587904.8055472   \n",
              "1893           AWS regions need to match docker-compose  1721587904.8055472   \n",
              "1894                                   Isort Pre-commit  1721587904.8055472   \n",
              "1895  How to destroy infrastructure created via GitH...  1721587904.8055472   \n",
              "\n",
              "             _dlt_id  \n",
              "0     s8QRrSS9f/cmWw  \n",
              "1     h1iiEnPJGYS3AQ  \n",
              "2     1R+PxYnDIBViUQ  \n",
              "3     cxWjOVFPwlU6Dw  \n",
              "4     o6O6Qfk2uS8bGA  \n",
              "...              ...  \n",
              "1891  MGMLRde8N5g56Q  \n",
              "1892  J6CaaWI1X5kc9w  \n",
              "1893  80E8GcLdtKhyCA  \n",
              "1894  EvAU90lgfL48rg  \n",
              "1895  w1QeflGrMY4kWQ  \n",
              "\n",
              "[1896 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-065ef7fc-f2a7-4122-8f0e-8ebd1eba408a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id__</th>\n",
              "      <th>vector__</th>\n",
              "      <th>text</th>\n",
              "      <th>section</th>\n",
              "      <th>question</th>\n",
              "      <th>_dlt_load_id</th>\n",
              "      <th>_dlt_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6176bb1f-204b-5283-9c2f-847c955b544c</td>\n",
              "      <td>[-0.00035094196, -0.062014297, -0.037999876, 0...</td>\n",
              "      <td>The purpose of this document is to capture fre...</td>\n",
              "      <td>General course-related questions</td>\n",
              "      <td>Course - When will the course start?</td>\n",
              "      <td>1721585669.31219</td>\n",
              "      <td>s8QRrSS9f/cmWw</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6db90087-445f-5ba0-9026-4c06ab5bfd96</td>\n",
              "      <td>[0.020011412, -0.011535538, 0.013017209, -0.00...</td>\n",
              "      <td>GitHub - DataTalksClub data-engineering-zoomca...</td>\n",
              "      <td>General course-related questions</td>\n",
              "      <td>Course - What are the prerequisites for this c...</td>\n",
              "      <td>1721585669.31219</td>\n",
              "      <td>h1iiEnPJGYS3AQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0387f46f-fc58-535e-8321-46076a15cfc6</td>\n",
              "      <td>[0.014857555, -0.06664993, -0.013571247, 0.023...</td>\n",
              "      <td>Yes, even if you don't register, you're still ...</td>\n",
              "      <td>General course-related questions</td>\n",
              "      <td>Course - Can I still join the course after the...</td>\n",
              "      <td>1721585669.31219</td>\n",
              "      <td>1R+PxYnDIBViUQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>78f94202-c34c-5710-bcb2-a71913d41144</td>\n",
              "      <td>[-0.023312032, -0.09461493, 0.056361612, -0.00...</td>\n",
              "      <td>You don't need it. You're accepted. You can al...</td>\n",
              "      <td>General course-related questions</td>\n",
              "      <td>Course - I have registered for the Data Engine...</td>\n",
              "      <td>1721585669.31219</td>\n",
              "      <td>cxWjOVFPwlU6Dw</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7edac7bb-a692-5c48-9933-a05a0c79bcd6</td>\n",
              "      <td>[0.026537651, -0.01779666, 0.0021155947, 0.006...</td>\n",
              "      <td>You can start by installing and setting up all...</td>\n",
              "      <td>General course-related questions</td>\n",
              "      <td>Course - What can I do before the course starts?</td>\n",
              "      <td>1721585669.31219</td>\n",
              "      <td>o6O6Qfk2uS8bGA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1891</th>\n",
              "      <td>739bfce7-8e24-5aa9-a67d-fdfa7a4e5b8b</td>\n",
              "      <td>[0.016619362, -0.033603165, -0.093347155, -0.0...</td>\n",
              "      <td>Problem description\\nThis is the step in the c...</td>\n",
              "      <td>Module 6: Best practices</td>\n",
              "      <td>Github actions: Permission denied error when e...</td>\n",
              "      <td>1721587904.8055472</td>\n",
              "      <td>MGMLRde8N5g56Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1892</th>\n",
              "      <td>e8299dc0-603c-5025-9437-2909594be446</td>\n",
              "      <td>[0.026872855, -0.0019949432, 0.008369081, -0.0...</td>\n",
              "      <td>Problem description\\nWhen a docker-compose fil...</td>\n",
              "      <td>Module 6: Best practices</td>\n",
              "      <td>Managing Multiple Docker Containers with docke...</td>\n",
              "      <td>1721587904.8055472</td>\n",
              "      <td>J6CaaWI1X5kc9w</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1893</th>\n",
              "      <td>4c627194-f4fa-545e-a0bd-0ccd53e775f8</td>\n",
              "      <td>[0.03513756, 0.056265566, 0.024428478, -0.0651...</td>\n",
              "      <td>Problem description\\nIf you are having problem...</td>\n",
              "      <td>Module 6: Best practices</td>\n",
              "      <td>AWS regions need to match docker-compose</td>\n",
              "      <td>1721587904.8055472</td>\n",
              "      <td>80E8GcLdtKhyCA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1894</th>\n",
              "      <td>1850e592-c31a-5c23-b811-5548dc41fa32</td>\n",
              "      <td>[0.033809766, -0.0031219206, 0.0017484799, 0.0...</td>\n",
              "      <td>Problem description\\nPre-commit command was fa...</td>\n",
              "      <td>Module 6: Best practices</td>\n",
              "      <td>Isort Pre-commit</td>\n",
              "      <td>1721587904.8055472</td>\n",
              "      <td>EvAU90lgfL48rg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1895</th>\n",
              "      <td>c4a194c4-eafe-5939-a721-49b249eef737</td>\n",
              "      <td>[-0.00075231574, 0.0042315223, 0.0025023425, -...</td>\n",
              "      <td>Problem description\\nInfrastructure created in...</td>\n",
              "      <td>Module 6: Best practices</td>\n",
              "      <td>How to destroy infrastructure created via GitH...</td>\n",
              "      <td>1721587904.8055472</td>\n",
              "      <td>w1QeflGrMY4kWQ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1896 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-065ef7fc-f2a7-4122-8f0e-8ebd1eba408a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-065ef7fc-f2a7-4122-8f0e-8ebd1eba408a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-065ef7fc-f2a7-4122-8f0e-8ebd1eba408a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c9ac27a3-addf-4cc9-99bf-433d8816966f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c9ac27a3-addf-4cc9-99bf-433d8816966f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c9ac27a3-addf-4cc9-99bf-433d8816966f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"db_table\",\n  \"rows\": 1896,\n  \"fields\": [\n    {\n      \"column\": \"id__\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1896,\n        \"samples\": [\n          \"6fceea7f-36dd-5467-b8a3-d49cfb7f2b0a\",\n          \"fbc361c8-8573-5b64-ac55-b5bacef7e5f3\",\n          \"77ced86f-6e3f-5180-bce9-bf08c1b16b32\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vector__\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 945,\n        \"samples\": [\n          \"Problem: The output of DictVectorizer was taking up too much memory. So much so, that I couldn\\u2019t even fit the linear regression model before running out of memory on my 16 GB machine.\\nSolution: In the example for DictVectorizer in the scikit-learn website, they set the parameter \\u201csparse\\u201d as False. Although this helps with viewing the results, this results in a lot of memory usage. The solution is to either use \\u201csparse=True\\u201d instead, or leave it at the default which is also True.\\nAhmed Fahim (afahim03@yahoo.com)\",\n          \"Link to Slack Thread : has anyone figured out how to read from GCP data lake instead of downloading all the taxi data again?\\nThere\\u2019s a few extra steps to go into reading from GCS with PySpark\\n1.)  IMPORTANT: Download the Cloud Storage connector for Hadoop here: https://cloud.google.com/dataproc/docs/concepts/connectors/cloud-storage#clusters\\nAs the name implies, this .jar file is what essentially connects PySpark with your GCS\\n2.) Move the .jar file to your Spark file directory. I installed Spark using homebrew on my MacOS machine and I had to create a /jars directory under \\\"/opt/homebrew/Cellar/apache-spark/3.2.1/ (where my spark dir is located)\\n3.) In your Python script, there are a few extra classes you\\u2019ll have to import:\\nimport pyspark\\nfrom pyspark.sql import SparkSession\\nfrom pyspark.conf import SparkConf\\nfrom pyspark.context import SparkContext\\n4.) You must set up your configurations before building your SparkSession. Here\\u2019s my code snippet:\\nconf = SparkConf() \\\\\\n.setMaster('local[*]') \\\\\\n.setAppName('test') \\\\\\n.set(\\\"spark.jars\\\", \\\"/opt/homebrew/Cellar/apache-spark/3.2.1/jars/gcs-connector-hadoop3-latest.jar\\\") \\\\\\n.set(\\\"spark.hadoop.google.cloud.auth.service.account.enable\\\", \\\"true\\\") \\\\\\n.set(\\\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\\\", \\\"path/to/google_credentials.json\\\")\\nsc = SparkContext(conf=conf)\\nsc._jsc.hadoopConfiguration().set(\\\"fs.AbstractFileSystem.gs.impl\\\",  \\\"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\\\")\\nsc._jsc.hadoopConfiguration().set(\\\"fs.gs.impl\\\", \\\"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\\\")\\nsc._jsc.hadoopConfiguration().set(\\\"fs.gs.auth.service.account.json.keyfile\\\", \\\"path/to/google_credentials.json\\\")\\nsc._jsc.hadoopConfiguration().set(\\\"fs.gs.auth.service.account.enable\\\", \\\"true\\\")\\n5.) Once you run that, build your SparkSession with the new parameters we\\u2019d just instantiated in the previous step:\\nspark = SparkSession.builder \\\\\\n.config(conf=sc.getConf()) \\\\\\n.getOrCreate()\\n6.) Finally, you\\u2019re able to read your files straight from GCS!\\ndf_green = spark.read.parquet(\\\"gs://{BUCKET}/green/202*/\\\")\",\n          \"1. Go to your dbt cloud service account\\n1. Adding the  [Storage Object Admin,Storage Admin] role in addition tco BigQuery Admin.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"section\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"Module 4: Deployment\",\n          \"3. Machine Learning for Classification\",\n          \"Miscellaneous\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 943,\n        \"samples\": [\n          \"WSL - Permissions too open at Windows\",\n          \"Why do we need the Staging dataset?\",\n          \"What if my answer is not exactly the same as the choices presented?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_dlt_load_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1721587904.8055472\",\n          \"1721585669.31219\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_dlt_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1896,\n        \"samples\": [\n          \"TZdkbTGIkJRqag\",\n          \"VMOOvydZ+EvWYw\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's all for this intro example! The DB could now be used as a basis for a RAG."
      ],
      "metadata": {
        "id": "L4yyirj_kI7h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create an up-to-date RAG with dlt and LanceDB"
      ],
      "metadata": {
        "id": "-OEpbMGNZexo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this demo, we will be creating an LLM chat bot that has the latest knowledge of the employee handbook of a fictional company. We will be able to chat to it about specific policies like PTO, work from home etc.\n",
        "\n",
        "To build this, we would need to do three things:\n",
        "1. The company policies exist in a [Notion Page](https://dlthub.notion.site/Employee-handbook-669c2a1e04044465811c8ca22977685d). We will need to first extract the text from these pages.\n",
        "2. Once extracted, we will want to embed them into vectors and then store them in a vector database.\n",
        "3. This will allow us to create our RAG: a function that would accept a user question, match it to the information stored in the vector database, and then send the question + relevant information as input to the LLM."
      ],
      "metadata": {
        "id": "Jh5v8-J8DcfA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WAJZRRkXmLPJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be using the following OSS tools for this:\n",
        "1. dlt for data ingestion:  \n",
        "  1. dlt can easily connect to any REST API source (like Notion)\n",
        "  2. It also has integrations with vector databases, like LanceDB.\n",
        "  3. It also allows to easily plug in functionality like incremental loading.\n",
        "2. LanceDB as a vector database:\n",
        "  1. LanceDB is an open-source vector database that is very easy to use and integrate into python workflows\n",
        "  2. It is in-process and serverless (like DuckDB), which makes querying and retreival very efficient\n",
        "3. Ollama for RAG:\n",
        "  1. Ollama is open-source and allows you to easily run LLMs locally"
      ],
      "metadata": {
        "id": "ZcObJq25L8o-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note on running this notebook**: We are going to download and use a local Ollama instance for the RAG, so preferably select the **T4 GPU** in the runtime when starting this notebook (Runtime > Change runtime type > Hardware accelerator > T4 GPU).\n",
        "\n",
        "You can also use the default CPU in case you're facing technical issues, but then your LLM responses might be slower (~2 mins/response)"
      ],
      "metadata": {
        "id": "zQUsxggP0tje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Create a Notion -> LanceDB pipeline using dlt"
      ],
      "metadata": {
        "id": "pAGJAVLzZCDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Install requirements"
      ],
      "metadata": {
        "id": "b5zDmfFcwS5M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To create a notion -> lancedb pipeline, we need to install:\n",
        "1. dlt with lancedb extras\n",
        "2. sentence-transformers: we need to use an embedding model to vectorize and store data inside LanceDB. For this we choose the open-source model \"sentence-transformers/all-MiniLM-L6-v2\"."
      ],
      "metadata": {
        "id": "aOUpcKhnwggh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install dlt[lancedb]==0.5.1a0\n",
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "4AVm0h1rjv8r"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Create a dlt project with rest_api source and lancedb destination"
      ],
      "metadata": {
        "id": "_aqwtE-Owslg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now create a dlt project using the command `dlt init <source> <destination>`."
      ],
      "metadata": {
        "id": "sS6gu1f_cO7E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This downloads all the modules required for the dlt source (rest api, in this case) into the local directory. See the side panel for the directory structure created."
      ],
      "metadata": {
        "id": "WFaBpJwzhkdT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the dlt rest api source?\n",
        "\n",
        "It is a dlt source that allows you to connect to any REST API endpoint using a declarative configuration. You can:\n",
        "- pass the endpoints that you want to connect to,\n",
        "- define the relation between the endpoints\n",
        "- define how you want to handle pagination and authentication"
      ],
      "metadata": {
        "id": "LD-Mfzl4hmsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yes | dlt init rest_api lancedb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gn5QwziOjqT9",
        "outputId": "704ac3ab-0f21-4f43-e27d-854e345c9ae3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking up the init scripts in \u001b[1mhttps://github.com/dlt-hub/verified-sources.git\u001b[0m...\n",
            "No files to update, exiting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Add API credentials"
      ],
      "metadata": {
        "id": "NqjfumInhWLK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To access APIs, databases, or any third-party applications, one might need to specify relevant credentials.\n",
        "\n",
        "With dlt, we can do it in two ways:\n",
        "1. Pass the credentials and any other sensitive information inside `.dlt/secrets.toml`\n",
        "  ```toml\n",
        "  [sources.rest_api.notion]\n",
        "  api_key = \"notion api key\"\n",
        "\n",
        "  [destination.lancedb]\n",
        "  embedding_model_provider = \"sentence-transformers\"\n",
        "  embedding_model = \"all-MiniLM-L6-v2\"\n",
        "\n",
        "  [destination.lancedb.credentials]\n",
        "  uri = \".lancedb\"\n",
        "  api_key = \"api_key\"\n",
        "  embedding_model_provider_api_key = \"embedding_model_provider_api_key\"\n",
        "  ```\n",
        "2. Pass them as environment variables\n",
        "  ```python\n",
        "  import os\n",
        "  \n",
        "  os.environ[\"SOURCES__REST_API__NOTION__API_KEY\"] = \"notion api key\"\n",
        "\n",
        "  os.environ[\"DESTINATION__LANCEDB__EMBEDDING_MODEL_PROVIDER\"] = \"sentence-transformers\"\n",
        "  os.environ[\"DESTINATION__LANCEDB__EMBEDDING_MODEL\"] = \"all-MiniLM-L6-v2\"\n",
        "\n",
        "  os.environ[\"DESTINATION__LANCEDB__CREDENTIALS__URI\"] = \".lancedb\"\n",
        "  os.environ[\"DESTINATION__LANCEDB__CREDENTIALS__API_KEY\"] = \"api_key\"\n",
        "  os.environ[\"DESTINATION__LANCEDB__CREDENTIALS__EMBEDDING_MODEL_PROVIDER_API_KEY\"] = \"embedding_model_provider_api_key\"\n",
        "  ```"
      ],
      "metadata": {
        "id": "LGO2s0xwlOMQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to be using option 2. It's not advisable to paste sensitive information like API keys inside the code, so instead we're going to include them inside the secrets tab in the side panel of the notebook. This will allow us to access the secret values from the notebook.\n",
        "\n",
        "Since we are using the OSS version of LanceDB and OSS embedding models, we only need to specify the API key for Notion.\n",
        "\n",
        "**Note**: You will need to copy the [notion API key](https://share.1password.com/s#da9KgMwPaZUaey3WCaD7ICJoyHDGd3Xos2EZ29WrSWQ) into the secrets tab under the name `SOURCES__REST_API__NOTION__API_KEY`. Make sure to enable notebook access after pasting the key."
      ],
      "metadata": {
        "id": "J1nF956xoqyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"SOURCES__REST_API__NOTION__API_KEY\"] = userdata.get(\"SOURCES__REST_API__NOTION__API_KEY\")\n",
        "\n",
        "os.environ[\"DESTINATION__LANCEDB__EMBEDDING_MODEL_PROVIDER\"] = \"sentence-transformers\"\n",
        "os.environ[\"DESTINATION__LANCEDB__EMBEDDING_MODEL\"] = \"all-MiniLM-L6-v2\"\n",
        "\n",
        "os.environ[\"DESTINATION__LANCEDB__CREDENTIALS__URI\"] = \".lancedb\""
      ],
      "metadata": {
        "id": "vSLP6qhNqafV"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Write the pipeline code"
      ],
      "metadata": {
        "id": "Eg9ySPDHtYLw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: We first go over the code step by step before putting it into runnable cells\n",
        "\n",
        "1. Import necessary modules (run this cell)"
      ],
      "metadata": {
        "id": "0PuHEBIVtl-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dlt\n",
        "from rest_api import RESTAPIConfig, rest_api_source\n",
        "\n",
        "from dlt.sources.helpers.rest_client.paginators import BasePaginator, JSONResponsePaginator\n",
        "from dlt.sources.helpers.requests import Response, Request\n",
        "\n",
        "from dlt.destinations.adapters import lancedb_adapter"
      ],
      "metadata": {
        "id": "BiA7UEAmtoFy"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Configure the dlt rest api source to connect to and extract the relevant data out from the Notion REST API.\n",
        "\n",
        "  Our notion space has multiple pages and each page has multiple paragraphs (called blocks). To extract all this data from the Notion API, we would first need to get a list of all the page_ids (each page has a unique page_id), and then use the page_id to request the contents from the individual pages. Specifically:\n",
        "  1. We will first request the page_ids from the `/search` endpoint\n",
        "  2. And then using the returned page_ids, we will request the contents from the `/blocks/{page_id}/children` endpoint\n",
        "\n",
        "  With this in mind, we can configure the dlt notion rest api source as follows:\n",
        "  ```python\n",
        "  RESTAPIConfig = {\n",
        "        \"client\": {\n",
        "            \"base_url\": \"https://api.notion.com/v1/\",\n",
        "            \"auth\": {\n",
        "                \"token\": dlt.secrets[\"sources.rest_api.notion.api_key\"]\n",
        "            },\n",
        "            \"headers\":{\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"Notion-Version\": \"2022-06-28\"\n",
        "            }\n",
        "        },\n",
        "        \"resources\": [\n",
        "            {\n",
        "                \"name\": \"search\",\n",
        "                \"endpoint\": {\n",
        "                    \"path\": \"search\",\n",
        "                    \"method\": \"POST\",\n",
        "                    \"paginator\": PostBodyPaginator(),\n",
        "                    \"json\": {\n",
        "                        \"query\": \"workshop\",\n",
        "                        \"sort\": {\n",
        "                            \"direction\": \"ascending\",\n",
        "                            \"timestamp\": \"last_edited_time\"\n",
        "                        }\n",
        "                    },\n",
        "                    \"data_selector\": \"results\"\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"page_content\",\n",
        "                \"endpoint\": {\n",
        "                    \"path\": \"blocks/{page_id}/children\",\n",
        "                    \"paginator\": JSONResponsePaginator(),\n",
        "                    \"params\": {\n",
        "                        \"page_id\": {\n",
        "                            \"type\": \"resolve\",\n",
        "                            \"resource\": \"search\",\n",
        "                            \"field\": \"id\"\n",
        "                        }\n",
        "                    },\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "    ```\n",
        "    Explanation:\n",
        "    1. `client`: Here we added our base url, headers, and authentication\n",
        "    2. `resources`: This is a list of endpoints that we wish to request data from (here: `/search` and `/blocks/{page_id}/children`)\n",
        "    3. [`/search`](https://developers.notion.com/reference/post-search) endpoint:\n",
        "      - The Notion API search endpoint allows us to filter pages based on the title. We can specify which pages we want returned based on the parameter \"query\". For example, if we'd like to return only those pages which has the word \"workshop\" in the title, then we would set `\"query\": \"workshop\"` in the json body.    \n",
        "      - As a response, it returns only page metadata (like page_id). Example response:\n",
        "      ```json\n",
        "          {\n",
        "            \"object\": \"list\",\n",
        "            \"results\": [\n",
        "              {\n",
        "                \"object\": \"page\",\n",
        "                \"id\": \"954b67f9-3f87-41db-8874-23b92bbd31ee\",\n",
        "                \"created_time\": \"2022-07-06T19:30:00.000Z\",\n",
        "                \"last_edited_time\": \"2022-07-06T19:30:00.000Z\",\n",
        "                .\n",
        "                .\n",
        "                .\n",
        "            ],\n",
        "            \"next_cursor\": null,\n",
        "            \"has_more\": false,\n",
        "            \"type\": \"page_or_database\",\n",
        "            \"page_or_database\": {}\n",
        "          }\n",
        "      ```\n",
        "      - This is how we would define our endpoint configuration for `/search`:\n",
        "      ```python\n",
        "           {\n",
        "             \"name\": \"search\",\n",
        "             \"endpoint\": {\n",
        "                 \"path\": \"search\",\n",
        "                 \"method\": \"POST\",\n",
        "                 \"paginator\": PostBodyPaginator(),\n",
        "                 \"json\": {\n",
        "                     \"query\": \"workshop\",\n",
        "                     \"sort\": {\n",
        "                         \"direction\": \"ascending\",\n",
        "                         \"timestamp\": \"last_edited_time\"\n",
        "                     }\n",
        "                 },\n",
        "                 \"data_selector\": \"results\"\n",
        "             }\n",
        "         },\n",
        "      ```\n",
        "      - `paginator` allows us to specify the pagination strategy relevant for the API and the endpoint. (More on this later)\n",
        "      - Since `/search` is a POST endpoint, we can include the json body inside the key `json`.\n",
        "      - We don't need the whole JSON response, but only the contents inside the field \"results\". We filter this out by specifying `\"data_selector\": \"results\"`.\n",
        "    4. [`blocks/{page_id}/children`](https://developers.notion.com/reference/get-block-children) endpoint:\n",
        "      - This is a GET point that returns a list of block objects (in our case, paragraphs) from a specific page.\n",
        "      - Since it accepts page_id as a parameter, we can pass this inside the key `params`\n",
        "      - We would like to be able to automatically fetch the page_ids returned from the `/search` endpoint and pass it as parameter into the endpoint `blocks/{page_id}/children`. We can do this by linking the two resources as follows:\n",
        "      ```python\n",
        "      {\n",
        "            \"name\": \"page_content\",\n",
        "            \"endpoint\": {\n",
        "                \"path\": \"blocks/{page_id}/children\",\n",
        "                \"paginator\": JSONResponsePaginator(),\n",
        "                \"params\": {\n",
        "                    \"page_id\": {\n",
        "                        \"type\": \"resolve\",\n",
        "                        \"resource\": \"search\",\n",
        "                        \"field\": \"id\"\n",
        "                    }\n",
        "                },\n",
        "            }\n",
        "      }\n",
        "      ```\n",
        "      - By specifying `\"type\":\"resolve\"`, we are letting dlt know that this parameter needs to be resolved from the parent resource `\"search\"` using the field `\"id\"`, which corresponds to the page id in the response of `/search`."
      ],
      "metadata": {
        "id": "-xcvRa42rZoz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  Note on pagination:\n",
        "\n",
        "  Different REST APIs might use different strategies to handle paginated responses. dlt has built-in support for [most common pagination mechanisms](https://dlthub.com/docs/general-usage/http/rest-client#paginators), and these can be explicity passed inside the configuration like shown above.\n",
        "\n",
        "  However in most cases, it won't be necessary to explicity specify the pagination strategy, since dlt detects it automatically.\n",
        "\n",
        "  In case the specific pagination is not supported by dlt yet, then you can also implement a custom paginator. For example, dlt does not have a built-in paginator for POST methods, so we write our own paginator. We take the [code provided in the docs for it](https://dlthub.com/docs/general-usage/http/rest-client#example-2-creating-a-paginator-for-post-requests), and make small modifications to it based on the [notion API documentation](https://developers.notion.com/reference/intro#parameters-for-paginated-requests).\n",
        "\n",
        "  ```python\n",
        "  class PostBodyPaginator(BasePaginator):\n",
        "      def __init__(self):\n",
        "          super().__init__()\n",
        "          self.cursor = None\n",
        "\n",
        "      def update_state(self, response: Response) -> None:\n",
        "          # Assuming the API returns an empty list when no more data is available\n",
        "          if not response.json():\n",
        "              self._has_next_page = False\n",
        "          else:\n",
        "              self.cursor = response.json().get(\"next_cursor\")\n",
        "              if self.cursor is None:\n",
        "                  self._has_next_page = False\n",
        "\n",
        "      def update_request(self, request: Request) -> None:\n",
        "          if request.json is None:\n",
        "              request.json = {}\n",
        "\n",
        "          # Add the cursor to the request body\n",
        "          request.json[\"start_cursor\"] = self.cursor\n",
        "  ```"
      ],
      "metadata": {
        "id": "LcJenlTNsBKS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Extract relevant content from the response body\n",
        "\n",
        "  The response returned from the API is a nested JSON which we need to pre-process before using it anywhere. dlt can unnest json automatically, but since the Notion API is a little tricky it's better to pre-process this first so we have a more structured DB as a result.\n",
        "  \n",
        "  One way to do this is to pass the JSON response through a transformation function that will extract only the relevant data from the JSON body (we later add this as a mapping to the resource):\n",
        "\n",
        "  ```python\n",
        "  def extract_page_content(response):\n",
        "      block_id = response[\"id\"]\n",
        "      last_edited_time = response[\"last_edited_time\"]\n",
        "      block_type = response.get(\"type\", \"Not paragraph\")\n",
        "      if block_type != \"paragraph\":\n",
        "          content = \"\"\n",
        "      else:\n",
        "          try:\n",
        "              content = response[\"paragraph\"][\"rich_text\"][0][\"plain_text\"]\n",
        "          except IndexError:\n",
        "              content = \"\"\n",
        "      return {\n",
        "          \"block_id\": block_id,\n",
        "          \"block_type\": block_type,\n",
        "          \"content\": content,\n",
        "          \"last_edited_time\": last_edited_time,\n",
        "          \"inserted_at_time\": datetime.now(timezone.utc)\n",
        "      }\n",
        "  ```\n",
        "  This is also where you could implement some sort of chunking strategy, but we will omit this in this example as the Notion text is already pre-chunked into paragraphs. Any data pre-processing can also happen here.\n",
        "\n",
        "  **Note**: If you want to include the parent page in the returned data, you can do so by including `response[\"parent\"][\"page_id\"]`. See 200 response example in the [Notion docs](https://developers.notion.com/reference/get-block-children).\n",
        "  \n",
        "  JSON response before the function:\n",
        "  ```\n",
        "  {\n",
        "      \"object\": \"list\",\n",
        "      \"results\": [\n",
        "        {\n",
        "          \"object\": \"block\",\n",
        "          \"id\": \"c02fc1d3-db8b-45c5-a222-27595b15aea7\",\n",
        "          \"created_time\": \"2022-03-01T19:05:00.000Z\",\n",
        "          \"last_edited_time\": \"2022-03-01T19:05:00.000Z\",\n",
        "          .\n",
        "          .\n",
        "          .\n",
        "          \"type\": \"paragraph\",\n",
        "          \"paragraph\": {\n",
        "            \"rich_text\": [\n",
        "              {\n",
        "                .\n",
        "                .\n",
        "                .\n",
        "                \"annotations\": {\n",
        "                  .\n",
        "                  .\n",
        "                  .\n",
        "\n",
        "                },\n",
        "                \"plain_text\": \"Lacinato kale is a variety of kale with a long tradition in Italian cuisine, especially that of Tuscany. It is also known as Tuscan kale, Italian kale, dinosaur kale, kale, flat back kale, palm tree kale, or black Tuscan palm.\",\n",
        "                \"href\": \"https://en.wikipedia.org/wiki/Lacinato_kale\"\n",
        "              }\n",
        "            ],\n",
        "            \"color\": \"default\"\n",
        "          }\n",
        "        }\n",
        "      ],\n",
        "      \"next_cursor\": null,\n",
        "      \"has_more\": false,\n",
        "      \"type\": \"block\",\n",
        "      \"block\": {}\n",
        "  }\n",
        "  ```\n",
        "  After passing it through the transformation function:\n",
        "\n",
        "  ```\n",
        "  {\n",
        "      \"block_id\": \"c02fc1d3-db8b-45c5-a222-27595b15aea7\",\n",
        "      \"block_type\": \"paragraph\",\n",
        "      \"content\": \"Lacinato kale is a variety of kale with a long tradition in Italian cuisine, especially that of Tuscany. It is also known as Tuscan kale, Italian kale, dinosaur kale, kale, flat back kale, palm tree kale, or black Tuscan palm.\",\n",
        "      \"last_edited_time\": \"2022-03-01T19:05:00.000Z\",\n",
        "  }\n",
        "\n",
        "    ```"
      ],
      "metadata": {
        "id": "tCeKKPz6spg3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Load the data incrementally\n",
        "\n",
        "  Incremental loading is a very important aspect of building scalable data pipelines. It is the technique of loading only the new or changed data since the last run of the pipeline.\n",
        "\n",
        "  In our case, when we first run the pipeline, all paragraphs from the employee handbook will get loaded as separate rows inside a lancedb table. Now if we change the content of one of the paragraphs and re-run the pipeline to update the table, then without doing incremental loading, one of two things may happen depending on the option we choose:\n",
        "  - If we choose the option \"replace\", then the existing data in lancedb will be dropped, and all of the paragraphs will be reloaded.\n",
        "  - If we choose the option \"append\", then the existing rows would remain and all of the paragraphs would be loaded again as new rows resulting in twice as many rows\n",
        "\n",
        "  To ensure that only the new/changed rows are loaded we would need the following pieces:\n",
        "  - A column that can keep track of changes in the row (Example: only load rows where `last_edited_time` is greater than the current maximum `last_edited_time`)\n",
        "  - A primary_key column that uniquely identify a row, so it's possible to track when the row changes\n",
        "  - A strategy to resolve changes in a single row (example: drop current and load the changed row)\n",
        "\n",
        "  This behaviour can be configured easily into a dlt rersource:\n",
        "  - Pass the incremental column as a parameter inside the resource\n",
        "    ```python\n",
        "    def rest_api_notion_incremental(\n",
        "      last_edited_time = dlt.sources.incremental(\"last_edited_time\", initial_value=\"2024-06-26T08:16:00.000Z\",primary_key=(\"block_id\"))\n",
        "    ):\n",
        "    ```\n",
        "    We choose the column `last_edited_time` since it keeps track of whenever a paragraph changes.\n",
        "  - Pass the following arguments inside `@dlt.resource` to define the strategy for dealing with duplicate rows:\n",
        "    - `write_disposition=\"merge\"`: ensures that any duplicate rows are merged on the primary key\n",
        "    - `primary_key=\"block_id\"`: specifies the primary key that we'd like to merge on. In our case, this is `block_id`, which is a unique id corresponding to each block (paragraph).\n",
        "    - `columns={\"last_edited_time\":{\"dedup_sort\":\"desc\"}}`: this specifies the deduplication strategy (how we would like to resolve duplicate rows). Here we chose to keep the row with the largest value of `last_edited_time`.\n",
        "\n",
        "    Putting it together:\n",
        "\n",
        "    ```python\n",
        "    @dlt.resource(\n",
        "        name=\"employee_handbook\",\n",
        "        write_disposition=\"merge\",\n",
        "        primary_key=\"block_id\",\n",
        "        columns={\"last_edited_time\":{\"dedup_sort\":\"desc\"}}\n",
        "    )\n",
        "    def rest_api_notion_incremental(\n",
        "        last_edited_time = dlt.sources.incremental(\"last_edited_time\", initial_value=\"2024-06-26T08:16:00.000Z\",primary_key=(\"block_id\"))\n",
        "    ):\n",
        "        for block in rest_api_notion_resource.add_map(extract_page_content):   \n",
        "            if not(len(block[\"content\"])):\n",
        "                continue\n",
        "            yield block\n",
        "  ```\n",
        "  Here, `rest_api_notion_resoure` yields the JSON response from the Notion REST API and `extract_page_content` is the transformation function that we pass the JSON response through."
      ],
      "metadata": {
        "id": "eTGdAXpKs8Pb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Create the pipeline and run it\n",
        "\n",
        "  With our source configured, we can now define the pipeline and run it.\n",
        "\n",
        "  Normally, to do this we would run  \n",
        "  ```python\n",
        "  pipeline.run(\n",
        "    rest_api_notion_incremental,\n",
        "    table_name=\"employee_handbook\",\n",
        "    write_disposition=\"merge\"\n",
        "  )\n",
        "  ```\n",
        "  and this would load the data into lancedb normally, without creating any embeddings.\n",
        "\n",
        "  However, we can have lancedb automatically create embeddings and load it along with the normal data using dlt's native adapter for lancedb: `lancedb_adapter`. It will use the embedding model that we specified in the credentials.   \n",
        "    \n",
        "  ```python\n",
        "  pipeline.run(\n",
        "    lancedb_adapter(\n",
        "      rest_api_notion_incremental,\n",
        "      embed=\"content\" # The column that we'd like to embed\n",
        "    )\n",
        "    table_name=\"employee_handbook\",\n",
        "    write_disposition=\"merge\"\n",
        "  )\n",
        "  ```"
      ],
      "metadata": {
        "id": "-dJlkDX0tSvP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Run the pipeline"
      ],
      "metadata": {
        "id": "Ll95duMkuKDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this block:"
      ],
      "metadata": {
        "id": "66l6khvmpDAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timezone\n",
        "\n",
        "class PostBodyPaginator(BasePaginator):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.cursor = None\n",
        "\n",
        "    def update_state(self, response: Response) -> None:\n",
        "        # Assuming the API returns an empty list when no more data is available\n",
        "        if not response.json():\n",
        "            self._has_next_page = False\n",
        "        else:\n",
        "            self.cursor = response.json().get(\"next_cursor\")\n",
        "            if self.cursor is None:\n",
        "                self._has_next_page = False\n",
        "\n",
        "    def update_request(self, request: Request) -> None:\n",
        "        if request.json is None:\n",
        "            request.json = {}\n",
        "\n",
        "        # Add the cursor to the request body\n",
        "        request.json[\"start_cursor\"] = self.cursor\n",
        "\n",
        "@dlt.resource(name=\"employee_handbook\")\n",
        "def rest_api_notion_resource():\n",
        "    notion_config: RESTAPIConfig = {\n",
        "        \"client\": {\n",
        "            \"base_url\": \"https://api.notion.com/v1/\",\n",
        "            \"auth\": {\n",
        "                \"token\": dlt.secrets[\"sources.rest_api.notion.api_key\"]\n",
        "            },\n",
        "            \"headers\":{\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"Notion-Version\": \"2022-06-28\"\n",
        "            }\n",
        "        },\n",
        "        \"resources\": [\n",
        "            {\n",
        "                \"name\": \"search\",\n",
        "                \"endpoint\": {\n",
        "                    \"path\": \"search\",\n",
        "                    \"method\": \"POST\",\n",
        "                    \"paginator\": PostBodyPaginator(),\n",
        "                    \"json\": {\n",
        "                        \"query\": \"workshop\",\n",
        "                        \"sort\": {\n",
        "                            \"direction\": \"ascending\",\n",
        "                            \"timestamp\": \"last_edited_time\"\n",
        "                        }\n",
        "                    },\n",
        "                    \"data_selector\": \"results\"\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"page_content\",\n",
        "                \"endpoint\": {\n",
        "                    \"path\": \"blocks/{page_id}/children\",\n",
        "                    \"paginator\": JSONResponsePaginator(),\n",
        "                    \"params\": {\n",
        "                        \"page_id\": {\n",
        "                            \"type\": \"resolve\",\n",
        "                            \"resource\": \"search\",\n",
        "                            \"field\": \"id\"\n",
        "                        }\n",
        "                    },\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    yield from rest_api_source(notion_config,name=\"employee_handbook\")\n",
        "\n",
        "def extract_page_content(response):\n",
        "    block_id = response[\"id\"]\n",
        "    last_edited_time = response[\"last_edited_time\"]\n",
        "    block_type = response.get(\"type\", \"Not paragraph\")\n",
        "    if block_type != \"paragraph\":\n",
        "        content = \"\"\n",
        "    else:\n",
        "        try:\n",
        "            content = response[\"paragraph\"][\"rich_text\"][0][\"plain_text\"]\n",
        "        except IndexError:\n",
        "            content = \"\"\n",
        "    return {\n",
        "        \"block_id\": block_id,\n",
        "        \"block_type\": block_type,\n",
        "        \"content\": content,\n",
        "        \"last_edited_time\": last_edited_time,\n",
        "        \"inserted_at_time\": datetime.now(timezone.utc)\n",
        "    }\n",
        "\n",
        "@dlt.resource(\n",
        "    name=\"employee_handbook\",\n",
        "    write_disposition=\"merge\",\n",
        "    primary_key=\"block_id\",\n",
        "    columns={\"last_edited_time\":{\"dedup_sort\":\"desc\"}}\n",
        "    )\n",
        "def rest_api_notion_incremental(\n",
        "    last_edited_time = dlt.sources.incremental(\"last_edited_time\", initial_value=\"2024-06-26T08:16:00.000Z\",primary_key=(\"block_id\"))\n",
        "):\n",
        "    # last_value = last_edited_time.last_value\n",
        "    # print(last_value)\n",
        "\n",
        "    for block in rest_api_notion_resource.add_map(extract_page_content):\n",
        "        if not(len(block[\"content\"])):\n",
        "            continue\n",
        "        yield block\n",
        "\n",
        "def load_notion() -> None:\n",
        "    pipeline = dlt.pipeline(\n",
        "        pipeline_name=\"company_policies\",\n",
        "        destination=\"lancedb\",\n",
        "        dataset_name=\"notion_pages\",\n",
        "        # full_refresh=True\n",
        "    )\n",
        "\n",
        "    load_info = pipeline.run(\n",
        "        lancedb_adapter(\n",
        "            rest_api_notion_incremental,\n",
        "            embed=\"content\"\n",
        "        ),\n",
        "        table_name=\"employee_handbook\",\n",
        "        write_disposition=\"merge\"\n",
        "    )\n",
        "    print(load_info)\n",
        "\n",
        "load_notion()"
      ],
      "metadata": {
        "id": "3RzeKOoNUsyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Visualize the output"
      ],
      "metadata": {
        "id": "ps09cty1uN9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lancedb\n",
        "\n",
        "db = lancedb.connect(\".lancedb\")\n",
        "dbtable = db.open_table(\"notion_pages___employee_handbook\")\n",
        "\n",
        "dbtable.to_pandas()"
      ],
      "metadata": {
        "id": "B7hsT5i8Y24S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ---"
      ],
      "metadata": {
        "id": "-4e3NR7a06eE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we make change to one of the paragraphs and run the pipeline again to see the effect of incremental loading. We observe two things:\n",
        "1. The column `inserted_at_time` only changed for the updated row, implying that only this row was added\n",
        "2. Looking at the primary key `block_id` we see that the original row was dropped and the updated row was inserted"
      ],
      "metadata": {
        "id": "A-3A-YWGuRCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db = lancedb.connect(\".lancedb\")\n",
        "dbtable = db.open_table(\"notion_pages___employee_handbook\")\n",
        "\n",
        "dbtable.to_pandas()"
      ],
      "metadata": {
        "id": "Sfp92r3iwlAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Create a RAG bot using Ollama"
      ],
      "metadata": {
        "id": "WuG395sV1rqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the contents from the employee handbook vectorized and stored in LanceDB, we're now ready to create our RAG with Ollama.\n"
      ],
      "metadata": {
        "id": "IDzsT3Ms2KgC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "What is RAG?\n",
        "\n",
        "Retrieval Automated Generation (RAG) is the framework of retrieving relevant documents from a database and passing it along with a query into an LLM so that the LLM can generate context-aware responses.\n",
        "\n",
        "In our case, if we were to ask an LLM questions about our specific employee policies, then we would not get useful responses because the LLM has never seen these policies. A solution to this could be to paste all of the policies into the prompt and then ask our questions. However, this would not be feasible given the limitations on the size of the context window.\n",
        "\n",
        "We can bypass this limitation using RAG:\n",
        "1. Given a user question, we would first embed this question into a vector\n",
        "2. Then we would do a vector search on our LanceDB table and retrieve top k results - which would be the most relevant paragraphs corresponding to the question\n",
        "3. Finally, we would pass the original question along with the retrieved paragraphs as a prompt into the LLM\n"
      ],
      "metadata": {
        "id": "Zln7JnrO11NQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Install Ollama into the notebook's local runtime"
      ],
      "metadata": {
        "id": "Fqvsji-Vuilq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "id": "kITCoZv85Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Start Ollama using `ollama serve`. This needs to run in the backgound - so we run it using `nohup` (to see the output log, open nohup.out)."
      ],
      "metadata": {
        "id": "5KrkKX5JuoiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup ollama serve > nohup.out 2>&1 &"
      ],
      "metadata": {
        "id": "Yp1cSSPn5FUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Pull the desired model. We're going to be using `llama1-uncensored` (takes about 1m to download)"
      ],
      "metadata": {
        "id": "HNqBkxbVu4af"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!ollama pull llama2-uncensored"
      ],
      "metadata": {
        "id": "S8HKNK7k5Xze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this next part we're going to be writing functions that accept user question, retrieve the relevant paragraphs from lancedb, and the pass the question and the retrieved pages as input into the ollama chat assistant"
      ],
      "metadata": {
        "id": "YxgV6a4O8J7n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. pip install ollama and import it"
      ],
      "metadata": {
        "id": "K5FCqdt-vCAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ollama"
      ],
      "metadata": {
        "id": "sQhykrlGZoId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ollama"
      ],
      "metadata": {
        "id": "2M4T3gF0bQQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Write a function that can retrieve content from lancedb relevant to the user query\n",
        "  \n",
        "  With LanceDB, you don't have to explicity embed the question. LanceDB stores information on the embedding model used and automatically embeds the question.\n",
        "\n",
        "  We use the `db_table.search()` function to query the DB and then limit it to the top 2 most similar results and return that as the context to pass to the RAG.\n",
        "\n",
        "  Limiting results is important because otherwise there might be too much confusing information. Similarly only picking the top choice might not give enough information."
      ],
      "metadata": {
        "id": "Nd2AzTLnvIuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_context_from_lancedb(dbtable, question, top_k=2):\n",
        "\n",
        "    query_results = dbtable.search(query=question).to_list()\n",
        "    context = \"\\n\".join([result[\"content\"] for result in query_results[:top_k]])\n",
        "\n",
        "    return context"
      ],
      "metadata": {
        "id": "c1rSQm33qx2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Finally we define a very basic RAG. We define a simple system prompt, retrieve the relevant context for the user query with the function defined above and then send the user question and the context to the `llama2-uncensored` model."
      ],
      "metadata": {
        "id": "MLiwo22GsVSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  # Connect to the lancedb table\n",
        "  db = lancedb.connect(\".lancedb\")\n",
        "  dbtable = db.open_table(\"notion_pages___employee_handbook\")\n",
        "\n",
        "  # A system prompt telling ollama to accept input in the form of \"Question: ... ; Context: ...\"\n",
        "  messages = [\n",
        "      {\"role\": \"system\", \"content\": \"You are a helpful assistant that helps users understand policies inside a company's employee handbook. The user will first ask you a question and then provide you relevant paragraphs from the handbook as context. Please answer the question based on the provided context. For any details missing in the paragraph, encourage the employee to contact the HR for that information. Please keep the responses conversational.\"}\n",
        "  ]\n",
        "\n",
        "  while True:\n",
        "    # Accept user question\n",
        "    question = input(\"You: \")\n",
        "\n",
        "    # Retrieve the relevant paragraphs on the question\n",
        "    context = retrieve_context_from_lancedb(dbtable,question,top_k=2)\n",
        "\n",
        "    # Create a user prompt using the question and retrieved context\n",
        "    messages.append(\n",
        "        {\"role\": \"user\", \"content\": f\"Question: '{question}'; Context:'{context}'\"}\n",
        "    )\n",
        "\n",
        "    # Get the response from the LLM\n",
        "    response = ollama.chat(\n",
        "        model=\"llama2-uncensored\",\n",
        "        messages=messages\n",
        "    )\n",
        "    response_content = response['message']['content']\n",
        "    print(f\"Assistant: {response_content}\")\n",
        "\n",
        "    # Add the response into the context window\n",
        "    messages.append(\n",
        "        {\"role\": \"assistant\", \"content\":response_content}\n",
        "    )"
      ],
      "metadata": {
        "id": "2OvqfvFU_h3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we run the RAG! Some example questions you can ask:\n",
        "\n",
        "* How many vacation days do I get?\n",
        "* Can I get maternity leave?\n",
        "\n",
        "**Note**: This is a very basic implementation of a RAG, since this workshop is mainly about data ingestion. So expect some weird answers. If you do stop and restart the cell, you will need to rerun the cell containing `ollama serve` first."
      ],
      "metadata": {
        "id": "OLlMA3pcq4RC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "id": "lCcHrjymfdgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's a lot more to learn and do with dlt and LanceDB, find more info the [dlt docs](https://dlthub.com/docs/) and the [LanceDB docs](https://lancedb.github.io/lancedb/)\n",
        "\n",
        "If you have questions about this workshop or dlt, feel free to join our [community on Slack](https://dlthub.com/community).\n",
        "\n",
        "If you're at EuroPython in Prague this week, come see us at our booth!"
      ],
      "metadata": {
        "id": "umpLwREgwyDi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HOMEWORK"
      ],
      "metadata": {
        "id": "SUX0qL8dsvjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timezone\n",
        "\n",
        "class PostBodyPaginator(BasePaginator):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.cursor = None\n",
        "\n",
        "    def update_state(self, response: Response) -> None:\n",
        "        # Assuming the API returns an empty list when no more data is available\n",
        "        if not response.json():\n",
        "            self._has_next_page = False\n",
        "        else:\n",
        "            self.cursor = response.json().get(\"next_cursor\")\n",
        "            if self.cursor is None:\n",
        "                self._has_next_page = False\n",
        "\n",
        "    def update_request(self, request: Request) -> None:\n",
        "        if request.json is None:\n",
        "            request.json = {}\n",
        "\n",
        "        # Add the cursor to the request body\n",
        "        request.json[\"start_cursor\"] = self.cursor\n",
        "\n",
        "@dlt.resource(name=\"homework\")\n",
        "def rest_api_notion_resource():\n",
        "    notion_config: RESTAPIConfig = {\n",
        "        \"client\": {\n",
        "            \"base_url\": \"https://api.notion.com/v1/\",\n",
        "            \"auth\": {\n",
        "                \"token\": dlt.secrets[\"sources.rest_api.notion.api_key\"]\n",
        "            },\n",
        "            \"headers\":{\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"Notion-Version\": \"2022-06-28\"\n",
        "            }\n",
        "        },\n",
        "        \"resources\": [\n",
        "            {\n",
        "                \"name\": \"search\",\n",
        "                \"endpoint\": {\n",
        "                    \"path\": \"search\",\n",
        "                    \"method\": \"POST\",\n",
        "                    \"paginator\": PostBodyPaginator(),\n",
        "                    \"json\": {\n",
        "                        \"query\": \"Homework: Employee handbook\",\n",
        "                        \"sort\": {\n",
        "                            \"direction\": \"ascending\",\n",
        "                            \"timestamp\": \"last_edited_time\"\n",
        "                        }\n",
        "                    },\n",
        "                    \"data_selector\": \"results\"\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"page_content\",\n",
        "                \"endpoint\": {\n",
        "                    \"path\": \"blocks/{page_id}/children\",\n",
        "                    \"paginator\": JSONResponsePaginator(),\n",
        "                    \"params\": {\n",
        "                        \"page_id\": {\n",
        "                            \"type\": \"resolve\",\n",
        "                            \"resource\": \"search\",\n",
        "                            \"field\": \"id\"\n",
        "                        }\n",
        "                    },\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    yield from rest_api_source(notion_config,name=\"homework\")\n",
        "\n",
        "def extract_page_content(response):\n",
        "    block_id = response[\"id\"]\n",
        "    last_edited_time = response[\"last_edited_time\"]\n",
        "    block_type = response.get(\"type\", \"Not paragraph\")\n",
        "    if block_type != \"paragraph\":\n",
        "        content = \"\"\n",
        "    else:\n",
        "        try:\n",
        "            content = response[\"paragraph\"][\"rich_text\"][0][\"plain_text\"]\n",
        "        except IndexError:\n",
        "            content = \"\"\n",
        "    return {\n",
        "        \"block_id\": block_id,\n",
        "        \"block_type\": block_type,\n",
        "        \"content\": content,\n",
        "        \"last_edited_time\": last_edited_time,\n",
        "        \"inserted_at_time\": datetime.now(timezone.utc)\n",
        "    }\n",
        "\n",
        "@dlt.resource(\n",
        "    name=\"homework\",\n",
        "    write_disposition=\"merge\",\n",
        "    primary_key=\"block_id\",\n",
        "    columns={\"last_edited_time\":{\"dedup_sort\":\"desc\"}}\n",
        "    )\n",
        "def rest_api_notion_incremental(\n",
        "    last_edited_time = dlt.sources.incremental(\"last_edited_time\", initial_value=\"2024-06-26T08:16:00.000Z\",primary_key=(\"block_id\"))\n",
        "):\n",
        "    last_value = last_edited_time.last_value\n",
        "    print(\"last_edited_time =  \",last_value)\n",
        "\n",
        "    for block in rest_api_notion_resource.add_map(extract_page_content):\n",
        "        if not(len(block[\"content\"])):\n",
        "            continue\n",
        "        yield block\n",
        "\n",
        "def load_notion() -> None:\n",
        "    pipeline = dlt.pipeline(\n",
        "        pipeline_name=\"company_policies\",\n",
        "        destination=\"lancedb\",\n",
        "        dataset_name=\"notion_pages\",\n",
        "        # full_refresh=True\n",
        "    )\n",
        "\n",
        "    load_info = pipeline.run(\n",
        "        lancedb_adapter(\n",
        "            rest_api_notion_incremental,\n",
        "            embed=\"content\"\n",
        "        ),\n",
        "        table_name=\"homework\",\n",
        "        write_disposition=\"merge\"\n",
        "    )\n",
        "    print(load_info)\n",
        "\n",
        "load_notion()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oBcv1rMDtjz",
        "outputId": "847ec408-52f3-47d5-ac34-f7b8353e104b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "last_edited_time =   2024-07-05T23:33:00.000Z\n",
            "Pipeline company_policies load step completed in ---\n",
            "0 load package(s) were loaded to destination LanceDB and into dataset None\n",
            "The LanceDB destination used <dlt.destinations.impl.lancedb.configuration.LanceDBCredentials object at 0x7c6f6ddcb490> location to store data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lancedb\n",
        "\n",
        "db = lancedb.connect(\".lancedb\")\n",
        "dbtable = db.open_table(\"notion_pages___homework\")\n",
        "\n",
        "dbtable.to_pandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xIF98FQzGORT",
        "outputId": "bbfc5373-9ca4-4395-b081-ac3445f8ca83"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    id__  \\\n",
              "0   c69f1ecf-7b02-5810-8286-3f42659ae9d4   \n",
              "1   f2c18ac0-50f5-5b72-a871-dc5a46780353   \n",
              "2   4553193e-c655-54df-9a33-cfc570bf34d0   \n",
              "3   791be1a1-6c67-530d-87ab-bd9912500ea5   \n",
              "4   a83497f4-922c-5d62-bab1-53804e93c811   \n",
              "5   434b71e9-a11a-519d-a9fe-e3ade78d47d6   \n",
              "6   17816363-54b7-5ba7-b8d5-06d871a25414   \n",
              "7   2a434cf9-09d9-5514-a88b-02977f2f953e   \n",
              "8   5f9384fa-7f98-5f52-a06e-05b05f42f69a   \n",
              "9   42af72f6-9db7-54a2-87b2-d466169078ff   \n",
              "10  8bfc36ce-cdb0-5792-bd70-d12ff22fc227   \n",
              "11  b1737a97-6dca-564c-a169-78e306a5e124   \n",
              "12  896f7ed8-e918-54f3-a7b8-565d53d6d22b   \n",
              "13  3557e3dd-de5b-51b9-bdee-b53ba588ed60   \n",
              "14  c51f99bf-5057-572e-bf9e-25dc03014c79   \n",
              "15  0317522c-a6db-59e8-ba5f-5ff0dc960d2e   \n",
              "16  4d0eb4d7-f0ad-517c-8165-7eb7932ea0ed   \n",
              "\n",
              "                                             vector__  \\\n",
              "0   [-0.024265623, 0.04746083, -0.011796438, 0.063...   \n",
              "1   [-0.049661573, 0.10853516, -0.0097625945, -0.0...   \n",
              "2   [-0.06316319, 0.17331506, 0.025351718, -0.0191...   \n",
              "3   [-0.10974315, 0.10586075, 0.0032906067, -0.021...   \n",
              "4   [0.052423306, -0.06457594, 0.065863, 0.0145438...   \n",
              "5   [0.0005233448, -0.054883398, 0.043573365, -0.0...   \n",
              "6   [0.03802632, -0.021509668, 0.0475278, 0.064706...   \n",
              "7   [-0.058588073, -0.07540443, 0.033775173, 0.009...   \n",
              "8   [-0.01359926, 0.004753031, 0.024835143, 0.0159...   \n",
              "9   [0.032060914, 0.02424462, 0.008471355, 0.03179...   \n",
              "10  [-0.013155272, 0.008382475, 0.017044408, 0.051...   \n",
              "11  [0.027987445, 0.06734361, 0.039806426, 0.00774...   \n",
              "12  [0.03252609, 0.008159482, 0.084435634, 0.05564...   \n",
              "13  [-0.0073140753, 0.01471069, -0.019091198, 0.02...   \n",
              "14  [-0.031538416, 0.034259938, -0.027282655, 0.02...   \n",
              "15  [-0.017366918, 0.06079061, 0.015769996, -0.014...   \n",
              "16  [0.033655427, 0.035742376, 0.039310906, 0.0037...   \n",
              "\n",
              "                                block_id block_type  \\\n",
              "0   a8196881-ae94-4767-8767-92fe1a327d24  paragraph   \n",
              "1   31fcbf26-2ca5-468a-8af8-d7eb4c2db8c8  paragraph   \n",
              "2   da7721fd-3d0f-4c04-bc5e-825ad60bed1c  paragraph   \n",
              "3   ff36dcf3-5faa-40b4-ad8e-92fdc952201e  paragraph   \n",
              "4   a1ff9697-4bb6-4f1e-b464-dda296dbd307  paragraph   \n",
              "5   e4ec9f4d-b687-4c28-a80d-985bfabcc2ba  paragraph   \n",
              "6   e6e550dc-b59e-4928-abd7-07eace948681  paragraph   \n",
              "7   a269d0ca-ce14-481b-a5f4-9192d6840d6e  paragraph   \n",
              "8   5b65f3e7-0a37-429a-818d-f99b53755ebd  paragraph   \n",
              "9   b27f7d80-f2f1-460e-aa0c-b8e770cf050a  paragraph   \n",
              "10  cf2c7276-9d6d-4611-97ef-e7707a668176  paragraph   \n",
              "11  79fd88bb-894c-4db3-961e-f2e9fa571399  paragraph   \n",
              "12  0b5f3660-7867-41ea-ae25-95585c3bb34e  paragraph   \n",
              "13  3153e9cf-44bf-4ec1-b835-67d37731f9bc  paragraph   \n",
              "14  b9d67165-1028-4edc-841b-fe2fd4cf0cf7  paragraph   \n",
              "15  72d2f585-a1b4-461e-ad88-45d9e3346425  paragraph   \n",
              "16  b1a9a976-eef2-4c99-9f57-3e5adb873d1f  paragraph   \n",
              "\n",
              "                                              content  \\\n",
              "0   We owe our success to our employees. To show o...   \n",
              "1   We want to ensure that private information abo...   \n",
              "2   Employee health is important to us. We don’t d...   \n",
              "3   Our company is dedicated to maintaining a safe...   \n",
              "4   If your job doesn’t require you to be present ...   \n",
              "5   Remote working refers to working from a non-of...   \n",
              "6   There are some expenses that we will pay direc...   \n",
              "7   Our company operates between 9 a.m. to 7 p.m. ...   \n",
              "8   In this section, we are going to be covering i...   \n",
              "9   Our company observes the following holidays: N...   \n",
              "10  These holidays are considered “off-days” for m...   \n",
              "11  Employees who are unable to work due to illnes...   \n",
              "12  Losing a loved one is traumatizing. If this ha...   \n",
              "13  In accordance with German law, we offer a comp...   \n",
              "14  We recognize the vital role that fathers and p...   \n",
              "15  Our company’s official dress code is Business ...   \n",
              "16  If you want to invite a visitor to our offices...   \n",
              "\n",
              "            last_edited_time                 inserted_at_time  \\\n",
              "0  2024-07-05 22:34:00+00:00 2024-07-21 18:17:45.888667+00:00   \n",
              "1  2024-07-05 22:38:00+00:00 2024-07-21 18:17:45.911805+00:00   \n",
              "2  2024-07-05 22:52:00+00:00 2024-07-21 18:17:45.912250+00:00   \n",
              "3  2024-07-05 22:52:00+00:00 2024-07-21 18:17:45.912608+00:00   \n",
              "4  2024-07-05 22:52:00+00:00 2024-07-21 18:17:45.912937+00:00   \n",
              "5  2024-07-05 22:52:00+00:00 2024-07-21 18:17:45.913259+00:00   \n",
              "6  2024-07-05 22:52:00+00:00 2024-07-21 18:17:45.913617+00:00   \n",
              "7  2024-07-05 22:52:00+00:00 2024-07-21 18:17:45.913965+00:00   \n",
              "8  2024-07-05 23:33:00+00:00 2024-07-21 18:17:45.914318+00:00   \n",
              "9  2024-07-05 22:52:00+00:00 2024-07-21 18:17:45.914631+00:00   \n",
              "10 2024-07-05 22:52:00+00:00 2024-07-21 18:17:45.914942+00:00   \n",
              "11 2024-07-05 22:52:00+00:00 2024-07-21 18:17:45.915239+00:00   \n",
              "12 2024-07-05 22:52:00+00:00 2024-07-21 18:17:45.915559+00:00   \n",
              "13 2024-07-05 22:52:00+00:00 2024-07-21 18:17:45.915861+00:00   \n",
              "14 2024-07-05 22:52:00+00:00 2024-07-21 18:17:45.916177+00:00   \n",
              "15 2024-07-05 22:54:00+00:00 2024-07-21 18:17:45.928873+00:00   \n",
              "16 2024-07-05 22:56:00+00:00 2024-07-21 18:17:45.929309+00:00   \n",
              "\n",
              "          _dlt_load_id         _dlt_id  \n",
              "0   1721585863.5398633  anKRMmydKdToSw  \n",
              "1   1721585863.5398633  KtqujCdo6qu6xg  \n",
              "2   1721585863.5398633  7VbJvyG5FEqsNQ  \n",
              "3   1721585863.5398633  WZU00XYokozZ1Q  \n",
              "4   1721585863.5398633  X0mgxpnXC8xE2A  \n",
              "5   1721585863.5398633  5KYPicmf/yIpKw  \n",
              "6   1721585863.5398633  IC81XAm9LQQyiw  \n",
              "7   1721585863.5398633  Srl63AK70q2fEg  \n",
              "8   1721585863.5398633  XjglZJ/ioA8fQA  \n",
              "9   1721585863.5398633  efra/7HR2he74A  \n",
              "10  1721585863.5398633  vnR4NJMBVqWmHg  \n",
              "11  1721585863.5398633  cjzeCDGFJsTwDA  \n",
              "12  1721585863.5398633  l4IKYzN0wCnXXw  \n",
              "13  1721585863.5398633  sOfwXuvfLrQ36w  \n",
              "14  1721585863.5398633  KTuhZ1MNs5zrFA  \n",
              "15  1721585863.5398633  8SM8l8CEHxa+vA  \n",
              "16  1721585863.5398633  Mx42L5TixeGzMQ  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ddc4ac9f-563b-4ffd-ae6a-d87dfd09f3b5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id__</th>\n",
              "      <th>vector__</th>\n",
              "      <th>block_id</th>\n",
              "      <th>block_type</th>\n",
              "      <th>content</th>\n",
              "      <th>last_edited_time</th>\n",
              "      <th>inserted_at_time</th>\n",
              "      <th>_dlt_load_id</th>\n",
              "      <th>_dlt_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c69f1ecf-7b02-5810-8286-3f42659ae9d4</td>\n",
              "      <td>[-0.024265623, 0.04746083, -0.011796438, 0.063...</td>\n",
              "      <td>a8196881-ae94-4767-8767-92fe1a327d24</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>We owe our success to our employees. To show o...</td>\n",
              "      <td>2024-07-05 22:34:00+00:00</td>\n",
              "      <td>2024-07-21 18:17:45.888667+00:00</td>\n",
              "      <td>1721585863.5398633</td>\n",
              "      <td>anKRMmydKdToSw</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>f2c18ac0-50f5-5b72-a871-dc5a46780353</td>\n",
              "      <td>[-0.049661573, 0.10853516, -0.0097625945, -0.0...</td>\n",
              "      <td>31fcbf26-2ca5-468a-8af8-d7eb4c2db8c8</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>We want to ensure that private information abo...</td>\n",
              "      <td>2024-07-05 22:38:00+00:00</td>\n",
              "      <td>2024-07-21 18:17:45.911805+00:00</td>\n",
              "      <td>1721585863.5398633</td>\n",
              "      <td>KtqujCdo6qu6xg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4553193e-c655-54df-9a33-cfc570bf34d0</td>\n",
              "      <td>[-0.06316319, 0.17331506, 0.025351718, -0.0191...</td>\n",
              "      <td>da7721fd-3d0f-4c04-bc5e-825ad60bed1c</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>Employee health is important to us. We don’t d...</td>\n",
              "      <td>2024-07-05 22:52:00+00:00</td>\n",
              "      <td>2024-07-21 18:17:45.912250+00:00</td>\n",
              "      <td>1721585863.5398633</td>\n",
              "      <td>7VbJvyG5FEqsNQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>791be1a1-6c67-530d-87ab-bd9912500ea5</td>\n",
              "      <td>[-0.10974315, 0.10586075, 0.0032906067, -0.021...</td>\n",
              "      <td>ff36dcf3-5faa-40b4-ad8e-92fdc952201e</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>Our company is dedicated to maintaining a safe...</td>\n",
              "      <td>2024-07-05 22:52:00+00:00</td>\n",
              "      <td>2024-07-21 18:17:45.912608+00:00</td>\n",
              "      <td>1721585863.5398633</td>\n",
              "      <td>WZU00XYokozZ1Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a83497f4-922c-5d62-bab1-53804e93c811</td>\n",
              "      <td>[0.052423306, -0.06457594, 0.065863, 0.0145438...</td>\n",
              "      <td>a1ff9697-4bb6-4f1e-b464-dda296dbd307</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>If your job doesn’t require you to be present ...</td>\n",
              "      <td>2024-07-05 22:52:00+00:00</td>\n",
              "      <td>2024-07-21 18:17:45.912937+00:00</td>\n",
              "      <td>1721585863.5398633</td>\n",
              "      <td>X0mgxpnXC8xE2A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>434b71e9-a11a-519d-a9fe-e3ade78d47d6</td>\n",
              "      <td>[0.0005233448, -0.054883398, 0.043573365, -0.0...</td>\n",
              "      <td>e4ec9f4d-b687-4c28-a80d-985bfabcc2ba</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>Remote working refers to working from a non-of...</td>\n",
              "      <td>2024-07-05 22:52:00+00:00</td>\n",
              "      <td>2024-07-21 18:17:45.913259+00:00</td>\n",
              "      <td>1721585863.5398633</td>\n",
              "      <td>5KYPicmf/yIpKw</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>17816363-54b7-5ba7-b8d5-06d871a25414</td>\n",
              "      <td>[0.03802632, -0.021509668, 0.0475278, 0.064706...</td>\n",
              "      <td>e6e550dc-b59e-4928-abd7-07eace948681</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>There are some expenses that we will pay direc...</td>\n",
              "      <td>2024-07-05 22:52:00+00:00</td>\n",
              "      <td>2024-07-21 18:17:45.913617+00:00</td>\n",
              "      <td>1721585863.5398633</td>\n",
              "      <td>IC81XAm9LQQyiw</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2a434cf9-09d9-5514-a88b-02977f2f953e</td>\n",
              "      <td>[-0.058588073, -0.07540443, 0.033775173, 0.009...</td>\n",
              "      <td>a269d0ca-ce14-481b-a5f4-9192d6840d6e</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>Our company operates between 9 a.m. to 7 p.m. ...</td>\n",
              "      <td>2024-07-05 22:52:00+00:00</td>\n",
              "      <td>2024-07-21 18:17:45.913965+00:00</td>\n",
              "      <td>1721585863.5398633</td>\n",
              "      <td>Srl63AK70q2fEg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5f9384fa-7f98-5f52-a06e-05b05f42f69a</td>\n",
              "      <td>[-0.01359926, 0.004753031, 0.024835143, 0.0159...</td>\n",
              "      <td>5b65f3e7-0a37-429a-818d-f99b53755ebd</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>In this section, we are going to be covering i...</td>\n",
              "      <td>2024-07-05 23:33:00+00:00</td>\n",
              "      <td>2024-07-21 18:17:45.914318+00:00</td>\n",
              "      <td>1721585863.5398633</td>\n",
              "      <td>XjglZJ/ioA8fQA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>42af72f6-9db7-54a2-87b2-d466169078ff</td>\n",
              "      <td>[0.032060914, 0.02424462, 0.008471355, 0.03179...</td>\n",
              "      <td>b27f7d80-f2f1-460e-aa0c-b8e770cf050a</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>Our company observes the following holidays: N...</td>\n",
              "      <td>2024-07-05 22:52:00+00:00</td>\n",
              "      <td>2024-07-21 18:17:45.914631+00:00</td>\n",
              "      <td>1721585863.5398633</td>\n",
              "      <td>efra/7HR2he74A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>8bfc36ce-cdb0-5792-bd70-d12ff22fc227</td>\n",
              "      <td>[-0.013155272, 0.008382475, 0.017044408, 0.051...</td>\n",
              "      <td>cf2c7276-9d6d-4611-97ef-e7707a668176</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>These holidays are considered “off-days” for m...</td>\n",
              "      <td>2024-07-05 22:52:00+00:00</td>\n",
              "      <td>2024-07-21 18:17:45.914942+00:00</td>\n",
              "      <td>1721585863.5398633</td>\n",
              "      <td>vnR4NJMBVqWmHg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>b1737a97-6dca-564c-a169-78e306a5e124</td>\n",
              "      <td>[0.027987445, 0.06734361, 0.039806426, 0.00774...</td>\n",
              "      <td>79fd88bb-894c-4db3-961e-f2e9fa571399</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>Employees who are unable to work due to illnes...</td>\n",
              "      <td>2024-07-05 22:52:00+00:00</td>\n",
              "      <td>2024-07-21 18:17:45.915239+00:00</td>\n",
              "      <td>1721585863.5398633</td>\n",
              "      <td>cjzeCDGFJsTwDA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>896f7ed8-e918-54f3-a7b8-565d53d6d22b</td>\n",
              "      <td>[0.03252609, 0.008159482, 0.084435634, 0.05564...</td>\n",
              "      <td>0b5f3660-7867-41ea-ae25-95585c3bb34e</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>Losing a loved one is traumatizing. If this ha...</td>\n",
              "      <td>2024-07-05 22:52:00+00:00</td>\n",
              "      <td>2024-07-21 18:17:45.915559+00:00</td>\n",
              "      <td>1721585863.5398633</td>\n",
              "      <td>l4IKYzN0wCnXXw</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3557e3dd-de5b-51b9-bdee-b53ba588ed60</td>\n",
              "      <td>[-0.0073140753, 0.01471069, -0.019091198, 0.02...</td>\n",
              "      <td>3153e9cf-44bf-4ec1-b835-67d37731f9bc</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>In accordance with German law, we offer a comp...</td>\n",
              "      <td>2024-07-05 22:52:00+00:00</td>\n",
              "      <td>2024-07-21 18:17:45.915861+00:00</td>\n",
              "      <td>1721585863.5398633</td>\n",
              "      <td>sOfwXuvfLrQ36w</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>c51f99bf-5057-572e-bf9e-25dc03014c79</td>\n",
              "      <td>[-0.031538416, 0.034259938, -0.027282655, 0.02...</td>\n",
              "      <td>b9d67165-1028-4edc-841b-fe2fd4cf0cf7</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>We recognize the vital role that fathers and p...</td>\n",
              "      <td>2024-07-05 22:52:00+00:00</td>\n",
              "      <td>2024-07-21 18:17:45.916177+00:00</td>\n",
              "      <td>1721585863.5398633</td>\n",
              "      <td>KTuhZ1MNs5zrFA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0317522c-a6db-59e8-ba5f-5ff0dc960d2e</td>\n",
              "      <td>[-0.017366918, 0.06079061, 0.015769996, -0.014...</td>\n",
              "      <td>72d2f585-a1b4-461e-ad88-45d9e3346425</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>Our company’s official dress code is Business ...</td>\n",
              "      <td>2024-07-05 22:54:00+00:00</td>\n",
              "      <td>2024-07-21 18:17:45.928873+00:00</td>\n",
              "      <td>1721585863.5398633</td>\n",
              "      <td>8SM8l8CEHxa+vA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>4d0eb4d7-f0ad-517c-8165-7eb7932ea0ed</td>\n",
              "      <td>[0.033655427, 0.035742376, 0.039310906, 0.0037...</td>\n",
              "      <td>b1a9a976-eef2-4c99-9f57-3e5adb873d1f</td>\n",
              "      <td>paragraph</td>\n",
              "      <td>If you want to invite a visitor to our offices...</td>\n",
              "      <td>2024-07-05 22:56:00+00:00</td>\n",
              "      <td>2024-07-21 18:17:45.929309+00:00</td>\n",
              "      <td>1721585863.5398633</td>\n",
              "      <td>Mx42L5TixeGzMQ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddc4ac9f-563b-4ffd-ae6a-d87dfd09f3b5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ddc4ac9f-563b-4ffd-ae6a-d87dfd09f3b5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ddc4ac9f-563b-4ffd-ae6a-d87dfd09f3b5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3da805ae-20b4-4236-9233-f637c47eeaa3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3da805ae-20b4-4236-9233-f637c47eeaa3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3da805ae-20b4-4236-9233-f637c47eeaa3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"dbtable\",\n  \"rows\": 17,\n  \"fields\": [\n    {\n      \"column\": \"id__\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"c69f1ecf-7b02-5810-8286-3f42659ae9d4\",\n          \"f2c18ac0-50f5-5b72-a871-dc5a46780353\",\n          \"434b71e9-a11a-519d-a9fe-e3ade78d47d6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vector__\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"block_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"a8196881-ae94-4767-8767-92fe1a327d24\",\n          \"31fcbf26-2ca5-468a-8af8-d7eb4c2db8c8\",\n          \"e4ec9f4d-b687-4c28-a80d-985bfabcc2ba\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"block_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"paragraph\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"We owe our success to our employees. To show our gratitude, we will invest in our employees professional development. We want employees to feel confident about improving their efficiency and productivity. We also want to help our employees achieve personal growth and success. Each employee has $1,000 annually to spend on educational activities or material. Subscriptions and books are included in this budget, unless they are necessary for you to complete your everyday duties. Send your expenses to HR by email. Apart from online courses, we offer these training opportunities: formal training sessions (individual or corporate, employee coaching and mentoring, seats at industry conferences, on-the-job training, job shadowing, job rotation. Development is a collective process. Team members and managers should regularly discuss learning needs and opportunities. And it\\u2019s HR\\u2019s responsibility to facilitate any development activities and processes.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"last_edited_time\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2024-07-05 22:34:00+00:00\",\n        \"max\": \"2024-07-05 23:33:00+00:00\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"2024-07-05 22:34:00+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"inserted_at_time\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2024-07-21 18:17:45.888667+00:00\",\n        \"max\": \"2024-07-21 18:17:45.929309+00:00\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"2024-07-21 18:17:45.888667+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_dlt_load_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"1721585863.5398633\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_dlt_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"anKRMmydKdToSw\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  # Connect to the lancedb table\n",
        "  db = lancedb.connect(\".lancedb\")\n",
        "  dbtable = db.open_table(\"notion_pages___homework\")\n",
        "\n",
        "  # A system prompt telling ollama to accept input in the form of \"Question: ... ; Context: ...\"\n",
        "  messages = [\n",
        "      {\"role\": \"system\", \"content\": \"You are a helpful assistant that helps users understand policies inside a company's employee handbook. The user will first ask you a question and then provide you relevant paragraphs from the handbook as context. Please answer the question based on the provided context. For any details missing in the paragraph, encourage the employee to contact the HR for that information. Please keep the responses conversational.\"}\n",
        "  ]\n",
        "\n",
        "  while True:\n",
        "    # Accept user question\n",
        "    question = input(\"You: \")\n",
        "\n",
        "    # Retrieve the relevant paragraphs on the question\n",
        "    context = retrieve_context_from_lancedb(dbtable,question,top_k=2)\n",
        "\n",
        "    # Create a user prompt using the question and retrieved context\n",
        "    messages.append(\n",
        "        {\"role\": \"user\", \"content\": f\"Question: '{question}'; Context:'{context}'\"}\n",
        "    )\n",
        "\n",
        "    # Get the response from the LLM\n",
        "    response = ollama.chat(\n",
        "        model=\"llama2-uncensored\",\n",
        "        messages=messages\n",
        "    )\n",
        "    response_content = response['message']['content']\n",
        "    print(f\"Assistant: {response_content}\")\n",
        "\n",
        "    # Add the response into the context window\n",
        "    messages.append(\n",
        "        {\"role\": \"assistant\", \"content\":response_content}\n",
        "    )"
      ],
      "metadata": {
        "id": "icFMOCjZGfrV"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "xh_cLVU_oRqn",
        "outputId": "ea18a780-37a2-4107-edd7-f6a0d09957d0"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: how many PTO days are the employees entitled to in a year?\n",
            "Assistant: The user is entitled to 30 days of paid time off (PTO) per year. They can earn an additional day for each subsequent year with the company, with a cap at 25 days overall. If they wish to use their PTO, they must send a request through the HRIS system and receive approval from their manager or HR. There are also certain holidays that may require employees to work, but any overtime hours worked on these holidays will be compensated with additional time off within 12 months after that day. If you need more information about PTO policies, please contact the HR department for clarification or specific details.\n",
            "You: End\n",
            "Assistant: Thank you for your question about bereavement leave. We understand that losing a loved one is a difficult experience, and we want to support our employees during this time. If an employee experiences the loss of a family member or close friend, they are entitled to five days of paid bereavement leave. Additional unpaid leave may also be requested if needed. Employees should inform their supervisor and HR as soon as possible so that arrangements can be made for the time off. We encourage employees to use their PTO if they need more time away from work, but we also want our employees to prioritize their emotional well-being during this difficult period.\n",
            "In terms of professional development opportunities, we are committed to investing in our employees' growth and success. Each employee has $1,000 annually to spend on educational activities or material. Subscriptions and books are included in this budget, unless they are necessary for the employee to complete their everyday duties. We offer a variety of development opportunities, including formal training sessions (individual or corporate), employee coaching and mentoring, seats at industry conferences, on-the-job training, job shadowing, and job rotation. Development is a collective process, and we encourage team members and managers to regularly discuss learning needs and opportunities. HR's role is to facilitate any development activities and processes.\n",
            "You: end Chat please\n",
            "Assistant: Thank you for your question about inviting visitors to our offices. We understand that having guests in the workplace can be exciting and beneficial, but we also want to ensure their safety and prevent any potential disruptions or conflicts. Before bringing a visitor to our office, please ask permission from our HR Manager first. You should also inform our reception of your guest's arrival so they may provide passes and assist with any necessary security measures.\n",
            "While you have guests in the office, it is important that you tend to them (especially when they are underage) and keep them away from areas where there are dangerous machines, chemicals, confidential records or sensitive equipment. Additionally, you should prevent your visitors from proselytizing your colleagues, gathering donations or requesting participation in activities while on our premises. Anyone who delivers orders, mail or packages for employees should remain at our building's reception or gate until they are collected by the appropriate employee.\n",
            "In terms of professional development opportunities, we are committed to investing in our employees' growth and success. Each employee has $1,000 annually to spend on educational activities or material. Subscriptions and books are included in this budget, unless they are necessary for the employee to complete their everyday duties. We offer a variety of development opportunities, including formal training sessions (individual or corporate), employee coaching and mentoring, seats at industry conferences, on-the-job training, job shadowing, and job rotation. Development is a collective process, and we encourage team members and managers to regularly discuss learning needs and opportunities. HR's role is to facilitate any development activities and processes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-263240bbee7e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-60-0dc58a88b370>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Accept user question\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Retrieve the relevant paragraphs on the question\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N0fiSmZAoVnD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}