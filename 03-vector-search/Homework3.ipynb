{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16374def-6a06-451c-b5b5-6b5d1a2c6c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: First value of the resulting vector: 0.07822261\n",
      "Number of filtered documents: 375\n",
      "filtered_documents[0] =  {'text': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository thereâ€™s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork', 'section': 'General course-related questions', 'question': 'How do I sign up?', 'course': 'machine-learning-zoomcamp', 'id': '0227b872'}\n",
      "Q2: Shape of X: (375, 768)\n",
      "Q3: Highest score in the results: 0.65065736\n",
      "ground_truth[0]  =   {'question': 'Where can I sign up for the course?', 'course': 'machine-learning-zoomcamp', 'document': '0227b872'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55cd9af6105b470a8e2f333751f0979d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import requests\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from elasticsearch import Elasticsearch\n",
    "import pandas as pd\n",
    "\n",
    "# Q1: Getting the embeddings model\n",
    "model_name = 'multi-qa-distilbert-cos-v1'\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "\n",
    "user_question = \"I just discovered the course. Can I still join it?\"\n",
    "user_question_embedding = embedding_model.encode(user_question)\n",
    "print(\"Q1: First value of the resulting vector:\", user_question_embedding[0])\n",
    "\n",
    "# Q2: Prepare the documents\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents = docs_response.json()\n",
    "\n",
    "# Filter for \"machine-learning-zoomcamp\"\n",
    "filtered_documents = [doc for doc in documents if doc['course'] == 'machine-learning-zoomcamp']\n",
    "print(\"Number of filtered documents:\", len(filtered_documents))\n",
    "print(\"filtered_documents[0] = \", filtered_documents[0])\n",
    "\n",
    "# Q2: Creating the embeddings\n",
    "embeddings = []\n",
    "for doc in filtered_documents:\n",
    "    qa_text = f\"{doc['question']} {doc['text']}\"\n",
    "    qa_embedding = embedding_model.encode(qa_text)\n",
    "    embeddings.append(qa_embedding)\n",
    "\n",
    "X = np.array(embeddings)\n",
    "print(\"Q2: Shape of X:\", X.shape)\n",
    "\n",
    "# Q3: Search\n",
    "v = user_question_embedding\n",
    "scores = X.dot(v)\n",
    "print(\"Q3: Highest score in the results:\", scores.max())\n",
    "\n",
    "# Q4. Hit-rate for our search engine\n",
    "class VectorSearchEngine:\n",
    "    def __init__(self, documents, embeddings):\n",
    "        self.documents = documents\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def search(self, v_query, num_results=10):\n",
    "        scores = self.embeddings.dot(v_query)\n",
    "        idx = np.argsort(-scores)[:num_results]\n",
    "        return [self.documents[i] for i in idx]\n",
    "\n",
    "# Create the search engine\n",
    "search_engine = VectorSearchEngine(documents=filtered_documents, embeddings=X)\n",
    "\n",
    "# Search for the top 5 results\n",
    "results = search_engine.search(v, num_results=5)\n",
    "# print(\"Search for the top 5 results\")\n",
    "# print(results)\n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/ground-truth-data.csv'\n",
    "ground_truth_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')\n",
    "print(\"ground_truth[0]  =  \", ground_truth[0])\n",
    "\n",
    "\n",
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(ground_truth, search_engine, num_results=5):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']\n",
    "        results = search_engine.search(embedding_model.encode(q['question']), num_results=5)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }\n",
    "\n",
    "metrics = evaluate( ground_truth, search_engine, num_results=5)\n",
    "print(f\"Q4:  Hit-rate: {metrics['hit_rate']:.2f}\")\n",
    "\n",
    "\n",
    "# Q5\n",
    "\n",
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"question_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"question_text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)\n",
    "\n",
    "for doc in tqdm(filtered_documents):\n",
    "    question = doc['question']\n",
    "    text = doc['text']\n",
    "    qt = question + ' ' + text\n",
    "\n",
    "    doc['question_vector'] = embedding_model.encode(question)\n",
    "    doc['text_vector'] = embedding_model.encode(text)\n",
    "    doc['question_text_vector'] = embedding_model.encode(qt)\n",
    "\n",
    "for doc in tqdm(filtered_documents):\n",
    "    es_client.index(index=index_name, document=doc)\n",
    "    \n",
    "\n",
    "knn = {\n",
    "    \"field\": 'question_text_vector',\n",
    "    \"query_vector\": user_question_embedding,\n",
    "    \"k\": 5,\n",
    "    \"num_candidates\": 10000,\n",
    "    \"filter\": {\n",
    "        \"term\": {\n",
    "            \"course\": 'machine-learning-zoomcamp'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "search_query = {\n",
    "    \"knn\": knn,\n",
    "    \"_source\": [\"text\", \"section\", \"question\", \"course\", \"id\"]\n",
    "}\n",
    "\n",
    "es_results = es_client.search(\n",
    "    index=index_name,\n",
    "    body=search_query\n",
    ")\n",
    "    \n",
    "print(\"Q5: What's the ID of the document with the highest score? \", es_results['hits']['hits'][0]['_source']['id'])\n",
    "\n",
    "\n",
    "# Q6\n",
    "\n",
    "\n",
    "def elastic_search_knn(field, vector, course, num_results=5):\n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": num_results,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"filter\": {\n",
    "            \"term\": {\n",
    "                \"course\": course\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"text\", \"section\", \"question\", \"course\", \"id\"]\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=search_query\n",
    "    )\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs\n",
    "\n",
    "\n",
    "\n",
    "def question_text_vector_knn(q, num_results=5):\n",
    "    question = q['question']\n",
    "    course = q['course']\n",
    "\n",
    "    v_q = embedding_model.encode(question)\n",
    "\n",
    "    return elastic_search_knn('question_text_vector', v_q, course, num_results= num_results)\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(ground_truth, search_engine, num_results=5):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']\n",
    "        results = search_engine(q, num_results=5)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }\n",
    "\n",
    "metrics = evaluate(ground_truth, question_text_vector_knn, num_results=5)\n",
    "print(f\"Q6: Hit-rate: {metrics['hit_rate']:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1294e793-d216-479d-9354-bf48ebfc4bac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
